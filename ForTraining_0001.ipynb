{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for Training for \"ForTraining_0001.csv\".\n",
    "\n",
    "### Data has two input columns/features/independent variables as numbers called A and B\n",
    "### 9 mathematical operations have been performed to generate 9 dependent numerical columns\n",
    "#### They are as below\n",
    "\n",
    "* Addition = A + B\n",
    "* Subtraction = A - B\n",
    "* Multiplication = A * B\n",
    "* Division = A / B\n",
    "* Sin(Addition) = sin (A + B)\n",
    "* Cos(Addition) = cos (A + B)\n",
    "* sqrt(Addition) = SQRT( A + B) if (A + B) >= 0 or -1.00 if (A +B ) < 0\n",
    "* 2 ^ Addition = 2 ^ (A +B)\n",
    "* Log(Addition) = log(A + B)\n",
    "\n",
    "### Additionally there is a dependent column present for classification training.\n",
    "* ODD_OR_EVEN(CEIL(A+B)) = If MODULUS of CEIL(A + B) = 0 then \"EVEN\" else \"ODD\" [To be used for *classification training *]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_DF = pd.read_csv(\"./ForTraining_0001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Addition</th>\n",
       "      <th>Subtraction</th>\n",
       "      <th>Multiplication</th>\n",
       "      <th>Division</th>\n",
       "      <th>Sin(Addition)</th>\n",
       "      <th>Cos(Addition)</th>\n",
       "      <th>Sqrt(Addition)</th>\n",
       "      <th>2^Addition</th>\n",
       "      <th>Log(Addition)</th>\n",
       "      <th>ODD_OR_EVEN(CEIL(A+B))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.93</td>\n",
       "      <td>9.06</td>\n",
       "      <td>18.99</td>\n",
       "      <td>0.87</td>\n",
       "      <td>89.97</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.36</td>\n",
       "      <td>520666.48</td>\n",
       "      <td>1.28</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.56</td>\n",
       "      <td>3.48</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-7.04</td>\n",
       "      <td>-12.39</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.52</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-15.76</td>\n",
       "      <td>-61.96</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.92</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-6.47</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.16</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.55</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-12.97</td>\n",
       "      <td>-41.18</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-2.84</td>\n",
       "      <td>6.22</td>\n",
       "      <td>3.38</td>\n",
       "      <td>-9.06</td>\n",
       "      <td>-17.66</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>1.84</td>\n",
       "      <td>10.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-5.01</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.37</td>\n",
       "      <td>-12.39</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>1.54</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4.74</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.92</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-26.33</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2.14</td>\n",
       "      <td>23.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-5.86</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>-5.83</td>\n",
       "      <td>0.18</td>\n",
       "      <td>195.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.79</td>\n",
       "      <td>-3.63</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A     B  Addition  Subtraction  Multiplication Division  \\\n",
       "0     9.93  9.06     18.99         0.87           89.97     1.10   \n",
       "1    -3.56  3.48     -0.08        -7.04          -12.39    -1.02   \n",
       "2    -7.52  8.24      0.72       -15.76          -61.96    -0.91   \n",
       "3    -1.92  3.37      1.45        -5.29           -6.47    -0.57   \n",
       "4    -5.55  7.42      1.87       -12.97          -41.18    -0.75   \n",
       "...    ...   ...       ...          ...             ...      ...   \n",
       "9995 -2.84  6.22      3.38        -9.06          -17.66    -0.46   \n",
       "9996 -5.01  7.38      2.37       -12.39          -36.97    -0.68   \n",
       "9997  4.74 -0.18      4.56         4.92           -0.85   -26.33   \n",
       "9998 -5.86 -0.03     -5.89        -5.83            0.18   195.33   \n",
       "9999  1.79 -3.63     -1.84         5.42           -6.50    -0.49   \n",
       "\n",
       "      Sin(Addition)  Cos(Addition)  Sqrt(Addition)  2^Addition Log(Addition)  \\\n",
       "0              0.14           0.99            4.36   520666.48          1.28   \n",
       "1             -0.08           1.00           -1.00        0.95         -1.00   \n",
       "2              0.66           0.75            0.85        1.65         -0.14   \n",
       "3              0.99           0.12            1.20        2.73          0.16   \n",
       "4              0.96          -0.29            1.37        3.66          0.27   \n",
       "...             ...            ...             ...         ...           ...   \n",
       "9995          -0.24          -0.97            1.84       10.41          0.53   \n",
       "9996           0.70          -0.72            1.54        5.17          0.37   \n",
       "9997          -0.99          -0.15            2.14       23.59          0.66   \n",
       "9998           0.38           0.92           -1.00        0.02         -1.00   \n",
       "9999          -0.96          -0.27           -1.00        0.28         -1.00   \n",
       "\n",
       "     ODD_OR_EVEN(CEIL(A+B))  \n",
       "0                       Odd  \n",
       "1                      Even  \n",
       "2                       Odd  \n",
       "3                      Even  \n",
       "4                      Even  \n",
       "...                     ...  \n",
       "9995                   Even  \n",
       "9996                    Odd  \n",
       "9997                    Odd  \n",
       "9998                    Odd  \n",
       "9999                    Odd  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Tensorflow:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 A = Master_DF.A, \n",
    "                 B = Master_DF.B, \n",
    "                 OutputVector=None, \n",
    "                 ClassificationOrRegression=\"Regression\"):\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.OutputVector = OutputVector\n",
    "        self.TypeOfTraining = ClassificationOrRegression\n",
    "        self.Training_DF = None\n",
    "        self.Test_DF = None\n",
    "        self.Model = None\n",
    "        self.Predicted_DF = None\n",
    "        self.TrainTestSplit()\n",
    "        \n",
    "    def TrainTestSplit(self, TestFractionSize=0.2):\n",
    "        self.Training_DF, self.Test_DF = train_test_split(Master_DF, test_size=TestFractionSize)\n",
    "        \n",
    "    def TrainTheModel(self, DenseNodeSize = 1000, batch_size=500, epochs=25, activation='linear',optimizer='sgd', loss='mean_squared_error'):\n",
    "        self.Model = tf.keras.Sequential()\n",
    "        self.Model.add(keras.layers.Dense(DenseNodeSize, activation=activation))\n",
    "        self.Model.add(keras.layers.Dense(DenseNodeSize, activation=activation))\n",
    "        self.Model.compile(optimizer=optimizer,loss=loss,metrics=[tf.keras.metrics.MeanSquaredLogarithmicError()])\n",
    "        xs = np.array([(a,b) for a,b in zip(self.Training_DF.A,self.Training_DF.B)])\n",
    "        ys = np.array(self.Training_DF[self.OutputVector], dtype='float')\n",
    "        self.Model.fit(xs,ys,batch_size=batch_size,epochs=epochs)\n",
    "        \n",
    "    def PredictTheResult(self):\n",
    "        self.Predicted_DF = pd.DataFrame(columns=['InputVals','PredictedVals','Difference'],dtype='float')\n",
    "        self.Predicted_DF.InputVals = self.Test_DF[self.OutputVector]\n",
    "        xs = np.array([(a,b) for a,b in zip(self.Test_DF.A,self.Test_DF.B)])\n",
    "        self.Predicted_DF.PredictedVals = self.Model.predict(xs)[:len(self.Test_DF)]\n",
    "        self.Predicted_DF.Difference = self.Predicted_DF.InputVals - self.Predicted_DF.PredictedVals\n",
    "        \n",
    "    def PredictOneVal(self, A=None, B=None):\n",
    "        return np.round(self.Model.predict(np.array([[A,B]]))[0][0],2)\n",
    "    \n",
    "    def PlotThePredicted_DF(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(self.Test_DF)),self.Predicted_DF.Difference)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us try to see if we can learn addition behavior between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2s 306us/sample - loss: 14.4239 - mean_squared_logarithmic_error: 0.2721\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.0134 - mean_squared_logarithmic_error: 9.5788e-04\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.0061 - mean_squared_logarithmic_error: 4.5052e-04\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.0031 - mean_squared_logarithmic_error: 2.3679e-04\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0017 - mean_squared_logarithmic_error: 1.2858e-04\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 9.7007e-04 - mean_squared_logarithmic_error: 7.4783e-05\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 5.6883e-04 - mean_squared_logarithmic_error: 4.3789e-05\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 3.4059e-04 - mean_squared_logarithmic_error: 2.6135e-05\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 2.0703e-04 - mean_squared_logarithmic_error: 1.6133e-05\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2s 261us/sample - loss: 1.2728e-04 - mean_squared_logarithmic_error: 9.8735e-06\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 7.8947e-05 - mean_squared_logarithmic_error: 6.2047e-06\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2s 262us/sample - loss: 4.9293e-05 - mean_squared_logarithmic_error: 3.8597e-06\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2s 261us/sample - loss: 3.0962e-05 - mean_squared_logarithmic_error: 2.4164e-06\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2s 265us/sample - loss: 1.9528e-05 - mean_squared_logarithmic_error: 1.5041e-06\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 1.2369e-05 - mean_squared_logarithmic_error: 9.6931e-07\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 2s 284us/sample - loss: 7.8556e-06 - mean_squared_logarithmic_error: 6.1489e-07\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2s 265us/sample - loss: 5.0070e-06 - mean_squared_logarithmic_error: 3.9352e-07\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 2s 283us/sample - loss: 3.1988e-06 - mean_squared_logarithmic_error: 2.5222e-07\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 2s 275us/sample - loss: 2.0486e-06 - mean_squared_logarithmic_error: 1.5993e-07\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2s 281us/sample - loss: 1.3153e-06 - mean_squared_logarithmic_error: 1.0343e-07\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2s 284us/sample - loss: 8.4651e-07 - mean_squared_logarithmic_error: 6.6733e-08\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 2s 308us/sample - loss: 5.4656e-07 - mean_squared_logarithmic_error: 4.2265e-08\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 3.5432e-07 - mean_squared_logarithmic_error: 2.7709e-08\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 2.3108e-07 - mean_squared_logarithmic_error: 1.8042e-08\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2s 307us/sample - loss: 1.5216e-07 - mean_squared_logarithmic_error: 1.1710e-08\n"
     ]
    }
   ],
   "source": [
    "AdditionTraining = Training_Tensorflow(OutputVector='Addition')\n",
    "AdditionTraining.TrainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdditionTraining.PredictOneVal(A=220,B=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdditionTraining.PredictTheResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AdditionTraining.PlotThePredicted_DF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us try to see if we can learn subtraction behavior between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2s 283us/sample - loss: 14.5417 - mean_squared_logarithmic_error: 0.2727\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2s 253us/sample - loss: 0.0142 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.0064 - mean_squared_logarithmic_error: 4.8997e-04\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0032 - mean_squared_logarithmic_error: 2.5011e-04\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2s 258us/sample - loss: 0.0017 - mean_squared_logarithmic_error: 1.3659e-04\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 9.8327e-04 - mean_squared_logarithmic_error: 7.6831e-05\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 5.6840e-04 - mean_squared_logarithmic_error: 4.4650e-05\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2s 261us/sample - loss: 3.3474e-04 - mean_squared_logarithmic_error: 2.6582e-05\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 1.9979e-04 - mean_squared_logarithmic_error: 1.6073e-05\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2s 262us/sample - loss: 1.2039e-04 - mean_squared_logarithmic_error: 9.6258e-06\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 7.3083e-05 - mean_squared_logarithmic_error: 5.7869e-06\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 4.4624e-05 - mean_squared_logarithmic_error: 3.5342e-06\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2s 263us/sample - loss: 2.7395e-05 - mean_squared_logarithmic_error: 2.2092e-06\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2s 265us/sample - loss: 1.6876e-05 - mean_squared_logarithmic_error: 1.3649e-06\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2s 266us/sample - loss: 1.0430e-05 - mean_squared_logarithmic_error: 8.4040e-07\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 2s 286us/sample - loss: 6.4646e-06 - mean_squared_logarithmic_error: 5.2222e-07\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 4.0174e-06 - mean_squared_logarithmic_error: 3.2588e-07\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 2s 263us/sample - loss: 2.5019e-06 - mean_squared_logarithmic_error: 2.0339e-07\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 1.5624e-06 - mean_squared_logarithmic_error: 1.2668e-07\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2s 280us/sample - loss: 9.7762e-07 - mean_squared_logarithmic_error: 7.9074e-08\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2s 271us/sample - loss: 6.1332e-07 - mean_squared_logarithmic_error: 5.0015e-08\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 2s 263us/sample - loss: 3.8599e-07 - mean_squared_logarithmic_error: 3.1425e-08\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 2s 262us/sample - loss: 2.4404e-07 - mean_squared_logarithmic_error: 1.9690e-08\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 1.5533e-07 - mean_squared_logarithmic_error: 1.2521e-08\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 1.0005e-07 - mean_squared_logarithmic_error: 8.0336e-09\n"
     ]
    }
   ],
   "source": [
    "SubtractionTraining = Training_Tensorflow(OutputVector='Subtraction')\n",
    "SubtractionTraining.TrainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubtractionTraining.PredictOneVal(A=30,B=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SubtractionTraining.PredictTheResult()\n",
    "SubtractionTraining.PlotThePredicted_DF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us try to see if we can learn multiplication behavior between A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 1130.5499 - mean_squared_logarithmic_error: 4.2376\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.5256 - mean_squared_logarithmic_error: 4.2474\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.5074 - mean_squared_logarithmic_error: 4.2562\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.4908 - mean_squared_logarithmic_error: 4.2634\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.4703 - mean_squared_logarithmic_error: 4.2712\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.4507 - mean_squared_logarithmic_error: 4.2756\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 1130.4375 - mean_squared_logarithmic_error: 4.2788\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 1130.4231 - mean_squared_logarithmic_error: 4.2835\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.4146 - mean_squared_logarithmic_error: 4.2885\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.4049 - mean_squared_logarithmic_error: 4.2900\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.3968 - mean_squared_logarithmic_error: 4.2886\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.3797 - mean_squared_logarithmic_error: 4.2922\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 1130.3682 - mean_squared_logarithmic_error: 4.2936\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.3676 - mean_squared_logarithmic_error: 4.2897\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 1130.3528 - mean_squared_logarithmic_error: 4.2860\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 1130.3444 - mean_squared_logarithmic_error: 4.2778\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 1130.3494 - mean_squared_logarithmic_error: 4.2725\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.3343 - mean_squared_logarithmic_error: 4.2764\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 1130.3294 - mean_squared_logarithmic_error: 4.2716\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 1130.3244 - mean_squared_logarithmic_error: 4.2623\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 1130.3232 - mean_squared_logarithmic_error: 4.2699\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 1130.3105 - mean_squared_logarithmic_error: 4.2612\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 1130.3142 - mean_squared_logarithmic_error: 4.2545\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 1130.3026 - mean_squared_logarithmic_error: 4.2419\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 1130.2994 - mean_squared_logarithmic_error: 4.2434\n"
     ]
    }
   ],
   "source": [
    "MultiplicationTraining = Training_Tensorflow(OutputVector='Multiplication')\n",
    "MultiplicationTraining.TrainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiplicationTraining.PredictOneVal(A=11,B=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiplicationTraining.PredictOneVal(A=5,B=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like it did a very bad job for multiplication. Given the code we can play with three parameters: number of nodes in each Dense layer, optimizer function, activation function and loss function. Let us first change Dense layer number of nodes. Let us double it and see if it helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 3s 356us/sample - loss: 1129.6121 - mean_squared_logarithmic_error: 4.3340\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2s 300us/sample - loss: 1129.5996 - mean_squared_logarithmic_error: 4.3372\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 3s 337us/sample - loss: 1129.5973 - mean_squared_logarithmic_error: 4.3401\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2s 306us/sample - loss: 1129.5899 - mean_squared_logarithmic_error: 4.3428\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2s 307us/sample - loss: 1129.5866 - mean_squared_logarithmic_error: 4.3459\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2s 311us/sample - loss: 1129.5772 - mean_squared_logarithmic_error: 4.3480\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2s 311us/sample - loss: 1129.5706 - mean_squared_logarithmic_error: 4.3515\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 1129.5678 - mean_squared_logarithmic_error: 4.3531\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2s 307us/sample - loss: 1129.5612 - mean_squared_logarithmic_error: 4.3542\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 1129.5587 - mean_squared_logarithmic_error: 4.3561\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2s 303us/sample - loss: 1129.5534 - mean_squared_logarithmic_error: 4.3529\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2s 309us/sample - loss: 1129.5497 - mean_squared_logarithmic_error: 4.3584\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2s 309us/sample - loss: 1129.5476 - mean_squared_logarithmic_error: 4.3556\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2s 305us/sample - loss: 1129.5407 - mean_squared_logarithmic_error: 4.3585\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 3s 324us/sample - loss: 1129.5375 - mean_squared_logarithmic_error: 4.3560\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 3s 338us/sample - loss: 1129.5335 - mean_squared_logarithmic_error: 4.3552\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 3s 342us/sample - loss: 1129.5266 - mean_squared_logarithmic_error: 4.3570\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 3s 322us/sample - loss: 1129.5257 - mean_squared_logarithmic_error: 4.3541\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 3s 364us/sample - loss: 1129.5279 - mean_squared_logarithmic_error: 4.3576\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2s 310us/sample - loss: 1129.5218 - mean_squared_logarithmic_error: 4.3531\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 3s 315us/sample - loss: 1129.5167 - mean_squared_logarithmic_error: 4.3543\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 3s 315us/sample - loss: 1129.5134 - mean_squared_logarithmic_error: 4.3491\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 3s 320us/sample - loss: 1129.5102 - mean_squared_logarithmic_error: 4.3502\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2s 311us/sample - loss: 1129.5073 - mean_squared_logarithmic_error: 4.3509\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2s 312us/sample - loss: 1129.5075 - mean_squared_logarithmic_error: 4.3438\n"
     ]
    }
   ],
   "source": [
    "MultiplicationTraining = Training_Tensorflow(OutputVector='Multiplication')\n",
    "MultiplicationTraining.TrainTheModel(DenseNodeSize=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like it didn't help much in this particular case. Let us go to the optimizer and activation and use adam optimizer + selu activation now and put back the number of nodes in dense layer back to 1000. We will also increase the epochs to 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/250\n",
      "8000/8000 [==============================] - 1s 140us/sample - loss: 1113.1812 - mean_squared_logarithmic_error: 4.0250\n",
      "Epoch 2/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1089.2133 - mean_squared_logarithmic_error: 3.7399\n",
      "Epoch 3/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1070.3270 - mean_squared_logarithmic_error: 3.7050\n",
      "Epoch 4/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1054.9777 - mean_squared_logarithmic_error: 3.6595\n",
      "Epoch 5/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1036.8264 - mean_squared_logarithmic_error: 3.2022\n",
      "Epoch 6/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1008.2480 - mean_squared_logarithmic_error: 2.4462\n",
      "Epoch 7/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 964.5374 - mean_squared_logarithmic_error: 1.8755\n",
      "Epoch 8/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 905.2212 - mean_squared_logarithmic_error: 1.5167\n",
      "Epoch 9/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 835.4823 - mean_squared_logarithmic_error: 1.3588\n",
      "Epoch 10/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 766.3220 - mean_squared_logarithmic_error: 1.2746\n",
      "Epoch 11/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 708.1030 - mean_squared_logarithmic_error: 1.2063\n",
      "Epoch 12/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 663.6666 - mean_squared_logarithmic_error: 1.0658\n",
      "Epoch 13/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 625.3687 - mean_squared_logarithmic_error: 0.8402\n",
      "Epoch 14/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 603.8154 - mean_squared_logarithmic_error: 0.7696\n",
      "Epoch 15/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 592.2807 - mean_squared_logarithmic_error: 0.7154\n",
      "Epoch 16/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 586.0191 - mean_squared_logarithmic_error: 0.6812\n",
      "Epoch 17/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 582.0667 - mean_squared_logarithmic_error: 0.6559\n",
      "Epoch 18/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 579.3653 - mean_squared_logarithmic_error: 0.6395\n",
      "Epoch 19/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 577.3924 - mean_squared_logarithmic_error: 0.6276\n",
      "Epoch 20/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 575.9546 - mean_squared_logarithmic_error: 0.6193\n",
      "Epoch 21/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 574.8494 - mean_squared_logarithmic_error: 0.6119\n",
      "Epoch 22/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 573.9410 - mean_squared_logarithmic_error: 0.6053\n",
      "Epoch 23/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 570.4444 - mean_squared_logarithmic_error: 0.5718\n",
      "Epoch 24/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 545.3135 - mean_squared_logarithmic_error: 0.3490\n",
      "Epoch 25/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 517.4891 - mean_squared_logarithmic_error: 0.1802\n",
      "Epoch 26/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 511.3321 - mean_squared_logarithmic_error: 0.1582\n",
      "Epoch 27/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 510.6263 - mean_squared_logarithmic_error: 0.1536\n",
      "Epoch 28/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 510.1412 - mean_squared_logarithmic_error: 0.1478\n",
      "Epoch 29/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 509.8566 - mean_squared_logarithmic_error: 0.1430\n",
      "Epoch 30/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 509.7073 - mean_squared_logarithmic_error: 0.1413\n",
      "Epoch 31/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 509.5277 - mean_squared_logarithmic_error: 0.1375\n",
      "Epoch 32/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 509.4013 - mean_squared_logarithmic_error: 0.1343\n",
      "Epoch 33/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 509.3112 - mean_squared_logarithmic_error: 0.1331\n",
      "Epoch 34/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 509.2309 - mean_squared_logarithmic_error: 0.1301\n",
      "Epoch 35/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 509.1849 - mean_squared_logarithmic_error: 0.1287\n",
      "Epoch 36/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 509.1429 - mean_squared_logarithmic_error: 0.1266\n",
      "Epoch 37/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 509.0915 - mean_squared_logarithmic_error: 0.1251\n",
      "Epoch 38/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 509.0648 - mean_squared_logarithmic_error: 0.1229\n",
      "Epoch 39/250\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 509.0511 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 40/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 509.0335 - mean_squared_logarithmic_error: 0.1202\n",
      "Epoch 41/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 509.0055 - mean_squared_logarithmic_error: 0.1187\n",
      "Epoch 42/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.9872 - mean_squared_logarithmic_error: 0.1184\n",
      "Epoch 43/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.9781 - mean_squared_logarithmic_error: 0.1170\n",
      "Epoch 44/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.9583 - mean_squared_logarithmic_error: 0.1156\n",
      "Epoch 45/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.9471 - mean_squared_logarithmic_error: 0.1146\n",
      "Epoch 46/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 508.9348 - mean_squared_logarithmic_error: 0.1150\n",
      "Epoch 47/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 508.9376 - mean_squared_logarithmic_error: 0.1130\n",
      "Epoch 48/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 508.9762 - mean_squared_logarithmic_error: 0.1135\n",
      "Epoch 49/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 508.9093 - mean_squared_logarithmic_error: 0.1111\n",
      "Epoch 50/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.8957 - mean_squared_logarithmic_error: 0.1118\n",
      "Epoch 51/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.8901 - mean_squared_logarithmic_error: 0.1104\n",
      "Epoch 52/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 508.8869 - mean_squared_logarithmic_error: 0.1103\n",
      "Epoch 53/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 508.8732 - mean_squared_logarithmic_error: 0.1101\n",
      "Epoch 54/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.8786 - mean_squared_logarithmic_error: 0.1091\n",
      "Epoch 55/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.8560 - mean_squared_logarithmic_error: 0.1089\n",
      "Epoch 56/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 508.8405 - mean_squared_logarithmic_error: 0.1094\n",
      "Epoch 57/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.8411 - mean_squared_logarithmic_error: 0.1067\n",
      "Epoch 58/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.8547 - mean_squared_logarithmic_error: 0.1081\n",
      "Epoch 59/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.8504 - mean_squared_logarithmic_error: 0.1079\n",
      "Epoch 60/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 508.8286 - mean_squared_logarithmic_error: 0.1067\n",
      "Epoch 61/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.8244 - mean_squared_logarithmic_error: 0.1070\n",
      "Epoch 62/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.7929 - mean_squared_logarithmic_error: 0.1064\n",
      "Epoch 63/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.8087 - mean_squared_logarithmic_error: 0.1066\n",
      "Epoch 64/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 508.7853 - mean_squared_logarithmic_error: 0.1053\n",
      "Epoch 65/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 508.7759 - mean_squared_logarithmic_error: 0.1042\n",
      "Epoch 66/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.7802 - mean_squared_logarithmic_error: 0.1051\n",
      "Epoch 67/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.7544 - mean_squared_logarithmic_error: 0.1040\n",
      "Epoch 68/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.7462 - mean_squared_logarithmic_error: 0.1046\n",
      "Epoch 69/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.7349 - mean_squared_logarithmic_error: 0.1044\n",
      "Epoch 70/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.7531 - mean_squared_logarithmic_error: 0.1036\n",
      "Epoch 71/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.7487 - mean_squared_logarithmic_error: 0.1034\n",
      "Epoch 72/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.7529 - mean_squared_logarithmic_error: 0.1017\n",
      "Epoch 73/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.7182 - mean_squared_logarithmic_error: 0.1029\n",
      "Epoch 74/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 508.7003 - mean_squared_logarithmic_error: 0.1013\n",
      "Epoch 75/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.6991 - mean_squared_logarithmic_error: 0.1013\n",
      "Epoch 76/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.6837 - mean_squared_logarithmic_error: 0.1018\n",
      "Epoch 77/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 508.6995 - mean_squared_logarithmic_error: 0.1004\n",
      "Epoch 78/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 508.6864 - mean_squared_logarithmic_error: 0.1010\n",
      "Epoch 79/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 508.6965 - mean_squared_logarithmic_error: 0.1004\n",
      "Epoch 80/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.6539 - mean_squared_logarithmic_error: 0.0987\n",
      "Epoch 81/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.6680 - mean_squared_logarithmic_error: 0.1002\n",
      "Epoch 82/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 508.6766 - mean_squared_logarithmic_error: 0.0976\n",
      "Epoch 83/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.6222 - mean_squared_logarithmic_error: 0.1005\n",
      "Epoch 84/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.6004 - mean_squared_logarithmic_error: 0.0973\n",
      "Epoch 85/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.6068 - mean_squared_logarithmic_error: 0.0991\n",
      "Epoch 86/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.5751 - mean_squared_logarithmic_error: 0.0970\n",
      "Epoch 87/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 508.6283 - mean_squared_logarithmic_error: 0.0968\n",
      "Epoch 88/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.5734 - mean_squared_logarithmic_error: 0.0978\n",
      "Epoch 89/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.5530 - mean_squared_logarithmic_error: 0.0955\n",
      "Epoch 90/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.5410 - mean_squared_logarithmic_error: 0.0954\n",
      "Epoch 91/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.5561 - mean_squared_logarithmic_error: 0.0962\n",
      "Epoch 92/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 508.5169 - mean_squared_logarithmic_error: 0.0947\n",
      "Epoch 93/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.5346 - mean_squared_logarithmic_error: 0.0941\n",
      "Epoch 94/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.5479 - mean_squared_logarithmic_error: 0.0938\n",
      "Epoch 95/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.5005 - mean_squared_logarithmic_error: 0.0931\n",
      "Epoch 96/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.4832 - mean_squared_logarithmic_error: 0.0923\n",
      "Epoch 97/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.4481 - mean_squared_logarithmic_error: 0.0921\n",
      "Epoch 98/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 508.4525 - mean_squared_logarithmic_error: 0.0927\n",
      "Epoch 99/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 508.4978 - mean_squared_logarithmic_error: 0.0909\n",
      "Epoch 100/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 508.4995 - mean_squared_logarithmic_error: 0.0897\n",
      "Epoch 101/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 508.3919 - mean_squared_logarithmic_error: 0.0895\n",
      "Epoch 102/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.3939 - mean_squared_logarithmic_error: 0.0891\n",
      "Epoch 103/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 508.3606 - mean_squared_logarithmic_error: 0.0888\n",
      "Epoch 104/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 508.3710 - mean_squared_logarithmic_error: 0.0881\n",
      "Epoch 105/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 508.3575 - mean_squared_logarithmic_error: 0.0874\n",
      "Epoch 106/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 508.3731 - mean_squared_logarithmic_error: 0.0865\n",
      "Epoch 107/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 508.3207 - mean_squared_logarithmic_error: 0.0849\n",
      "Epoch 108/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 508.2876 - mean_squared_logarithmic_error: 0.0857\n",
      "Epoch 109/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 508.2963 - mean_squared_logarithmic_error: 0.0835\n",
      "Epoch 110/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.2558 - mean_squared_logarithmic_error: 0.0850\n",
      "Epoch 111/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 508.2650 - mean_squared_logarithmic_error: 0.0821\n",
      "Epoch 112/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.2227 - mean_squared_logarithmic_error: 0.0825\n",
      "Epoch 113/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 508.2156 - mean_squared_logarithmic_error: 0.0807\n",
      "Epoch 114/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 508.2310 - mean_squared_logarithmic_error: 0.0802\n",
      "Epoch 115/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 508.1882 - mean_squared_logarithmic_error: 0.0804\n",
      "Epoch 116/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 508.1462 - mean_squared_logarithmic_error: 0.0791\n",
      "Epoch 117/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 508.1166 - mean_squared_logarithmic_error: 0.0777\n",
      "Epoch 118/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.0986 - mean_squared_logarithmic_error: 0.0770\n",
      "Epoch 119/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 508.0909 - mean_squared_logarithmic_error: 0.0765\n",
      "Epoch 120/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.0553 - mean_squared_logarithmic_error: 0.0738\n",
      "Epoch 121/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.0533 - mean_squared_logarithmic_error: 0.0744\n",
      "Epoch 122/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 508.0026 - mean_squared_logarithmic_error: 0.0737\n",
      "Epoch 123/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.9887 - mean_squared_logarithmic_error: 0.0708\n",
      "Epoch 124/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.9787 - mean_squared_logarithmic_error: 0.0709\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 95us/sample - loss: 508.0314 - mean_squared_logarithmic_error: 0.0703\n",
      "Epoch 126/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 508.0047 - mean_squared_logarithmic_error: 0.0688\n",
      "Epoch 127/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.9217 - mean_squared_logarithmic_error: 0.0662\n",
      "Epoch 128/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.8855 - mean_squared_logarithmic_error: 0.0650\n",
      "Epoch 129/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.8498 - mean_squared_logarithmic_error: 0.0642\n",
      "Epoch 130/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 507.8093 - mean_squared_logarithmic_error: 0.0622\n",
      "Epoch 131/250\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 507.7739 - mean_squared_logarithmic_error: 0.0617\n",
      "Epoch 132/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 507.7512 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 133/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.7254 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 134/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 507.6892 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 135/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.6361 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 136/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 507.6041 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 137/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 507.5770 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 138/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 507.5755 - mean_squared_logarithmic_error: 0.0534\n",
      "Epoch 139/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 507.5335 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 140/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.4865 - mean_squared_logarithmic_error: 0.0531\n",
      "Epoch 141/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 507.4656 - mean_squared_logarithmic_error: 0.0523\n",
      "Epoch 142/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.4185 - mean_squared_logarithmic_error: 0.0507\n",
      "Epoch 143/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 507.3874 - mean_squared_logarithmic_error: 0.0509\n",
      "Epoch 144/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 507.3836 - mean_squared_logarithmic_error: 0.0501\n",
      "Epoch 145/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.3799 - mean_squared_logarithmic_error: 0.0511\n",
      "Epoch 146/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 507.3213 - mean_squared_logarithmic_error: 0.0495\n",
      "Epoch 147/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.2936 - mean_squared_logarithmic_error: 0.0499\n",
      "Epoch 148/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 507.2795 - mean_squared_logarithmic_error: 0.0503\n",
      "Epoch 149/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 507.2379 - mean_squared_logarithmic_error: 0.0485\n",
      "Epoch 150/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 507.1930 - mean_squared_logarithmic_error: 0.0499\n",
      "Epoch 151/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 507.1653 - mean_squared_logarithmic_error: 0.0494\n",
      "Epoch 152/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.1352 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 153/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 507.1179 - mean_squared_logarithmic_error: 0.0491\n",
      "Epoch 154/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 507.0822 - mean_squared_logarithmic_error: 0.0489\n",
      "Epoch 155/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 507.0526 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 156/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 507.0522 - mean_squared_logarithmic_error: 0.0497\n",
      "Epoch 157/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 507.0569 - mean_squared_logarithmic_error: 0.0500\n",
      "Epoch 158/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 506.9855 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 159/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 506.9949 - mean_squared_logarithmic_error: 0.0494\n",
      "Epoch 160/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 507.0148 - mean_squared_logarithmic_error: 0.0497\n",
      "Epoch 161/250\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 506.9870 - mean_squared_logarithmic_error: 0.0493\n",
      "Epoch 162/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 506.9029 - mean_squared_logarithmic_error: 0.0489\n",
      "Epoch 163/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 506.8921 - mean_squared_logarithmic_error: 0.0495\n",
      "Epoch 164/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 506.8846 - mean_squared_logarithmic_error: 0.0490\n",
      "Epoch 165/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 506.8532 - mean_squared_logarithmic_error: 0.0495\n",
      "Epoch 166/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 506.8870 - mean_squared_logarithmic_error: 0.0496\n",
      "Epoch 167/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 506.9774 - mean_squared_logarithmic_error: 0.0502\n",
      "Epoch 168/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 506.8175 - mean_squared_logarithmic_error: 0.0497\n",
      "Epoch 169/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 506.7738 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 170/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 506.7670 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 171/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 506.7537 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 172/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 506.7400 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 173/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 506.7467 - mean_squared_logarithmic_error: 0.0487\n",
      "Epoch 174/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 506.7248 - mean_squared_logarithmic_error: 0.0474\n",
      "Epoch 175/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 506.6836 - mean_squared_logarithmic_error: 0.0476\n",
      "Epoch 176/250\n",
      "8000/8000 [==============================] - 1s 130us/sample - loss: 506.6641 - mean_squared_logarithmic_error: 0.0471\n",
      "Epoch 177/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 506.6765 - mean_squared_logarithmic_error: 0.0474\n",
      "Epoch 178/250\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 506.6566 - mean_squared_logarithmic_error: 0.0471\n",
      "Epoch 179/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 506.6683 - mean_squared_logarithmic_error: 0.0464\n",
      "Epoch 180/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 506.6130 - mean_squared_logarithmic_error: 0.0468\n",
      "Epoch 181/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 506.6082 - mean_squared_logarithmic_error: 0.0462\n",
      "Epoch 182/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.5699 - mean_squared_logarithmic_error: 0.0454\n",
      "Epoch 183/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 506.5725 - mean_squared_logarithmic_error: 0.0451\n",
      "Epoch 184/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.5421 - mean_squared_logarithmic_error: 0.0454\n",
      "Epoch 185/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 506.5469 - mean_squared_logarithmic_error: 0.0446\n",
      "Epoch 186/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 506.5189 - mean_squared_logarithmic_error: 0.0437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 506.5022 - mean_squared_logarithmic_error: 0.0434\n",
      "Epoch 188/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 506.4965 - mean_squared_logarithmic_error: 0.0430\n",
      "Epoch 189/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 506.4716 - mean_squared_logarithmic_error: 0.0419\n",
      "Epoch 190/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 506.4577 - mean_squared_logarithmic_error: 0.0426\n",
      "Epoch 191/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 506.4478 - mean_squared_logarithmic_error: 0.0412\n",
      "Epoch 192/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 506.4217 - mean_squared_logarithmic_error: 0.0405\n",
      "Epoch 193/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 506.4001 - mean_squared_logarithmic_error: 0.0402\n",
      "Epoch 194/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 506.3870 - mean_squared_logarithmic_error: 0.0399\n",
      "Epoch 195/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 506.3772 - mean_squared_logarithmic_error: 0.0390\n",
      "Epoch 196/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 506.3700 - mean_squared_logarithmic_error: 0.0386\n",
      "Epoch 197/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 506.4201 - mean_squared_logarithmic_error: 0.0394\n",
      "Epoch 198/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 506.3581 - mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 199/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 506.3522 - mean_squared_logarithmic_error: 0.0375\n",
      "Epoch 200/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 506.3554 - mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 201/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 506.2993 - mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 202/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 506.2772 - mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 203/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 506.2743 - mean_squared_logarithmic_error: 0.0347\n",
      "Epoch 204/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.2675 - mean_squared_logarithmic_error: 0.0337\n",
      "Epoch 205/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 506.2845 - mean_squared_logarithmic_error: 0.0336\n",
      "Epoch 206/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 506.2523 - mean_squared_logarithmic_error: 0.0330\n",
      "Epoch 207/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.2572 - mean_squared_logarithmic_error: 0.0328\n",
      "Epoch 208/250\n",
      "8000/8000 [==============================] - 1s 126us/sample - loss: 506.2643 - mean_squared_logarithmic_error: 0.0317\n",
      "Epoch 209/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 506.2624 - mean_squared_logarithmic_error: 0.0323\n",
      "Epoch 210/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 506.2032 - mean_squared_logarithmic_error: 0.0313\n",
      "Epoch 211/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 506.1529 - mean_squared_logarithmic_error: 0.0298\n",
      "Epoch 212/250\n",
      "8000/8000 [==============================] - 1s 126us/sample - loss: 506.1597 - mean_squared_logarithmic_error: 0.0294\n",
      "Epoch 213/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 506.1410 - mean_squared_logarithmic_error: 0.0290\n",
      "Epoch 214/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 506.1446 - mean_squared_logarithmic_error: 0.0288\n",
      "Epoch 215/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.1037 - mean_squared_logarithmic_error: 0.0277\n",
      "Epoch 216/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 506.1172 - mean_squared_logarithmic_error: 0.0276\n",
      "Epoch 217/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 506.0801 - mean_squared_logarithmic_error: 0.0271\n",
      "Epoch 218/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 506.0646 - mean_squared_logarithmic_error: 0.0262\n",
      "Epoch 219/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 506.0576 - mean_squared_logarithmic_error: 0.0257\n",
      "Epoch 220/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 506.0390 - mean_squared_logarithmic_error: 0.0254\n",
      "Epoch 221/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.0309 - mean_squared_logarithmic_error: 0.0249\n",
      "Epoch 222/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 506.0225 - mean_squared_logarithmic_error: 0.0241\n",
      "Epoch 223/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 506.0049 - mean_squared_logarithmic_error: 0.0237\n",
      "Epoch 224/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 506.0069 - mean_squared_logarithmic_error: 0.0234\n",
      "Epoch 225/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 505.9986 - mean_squared_logarithmic_error: 0.0230\n",
      "Epoch 226/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 505.9771 - mean_squared_logarithmic_error: 0.0224\n",
      "Epoch 227/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 505.9579 - mean_squared_logarithmic_error: 0.0221\n",
      "Epoch 228/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 505.9685 - mean_squared_logarithmic_error: 0.0217\n",
      "Epoch 229/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 505.9930 - mean_squared_logarithmic_error: 0.0219\n",
      "Epoch 230/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 505.9627 - mean_squared_logarithmic_error: 0.0208\n",
      "Epoch 231/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 505.9544 - mean_squared_logarithmic_error: 0.0202 - loss: 487.4817 - mean_squared_logarit\n",
      "Epoch 232/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 505.9144 - mean_squared_logarithmic_error: 0.0197\n",
      "Epoch 233/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 505.9093 - mean_squared_logarithmic_error: 0.0192\n",
      "Epoch 234/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 505.8901 - mean_squared_logarithmic_error: 0.0187\n",
      "Epoch 235/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 505.8846 - mean_squared_logarithmic_error: 0.0184\n",
      "Epoch 236/250\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 505.8792 - mean_squared_logarithmic_error: 0.0182\n",
      "Epoch 237/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 505.8637 - mean_squared_logarithmic_error: 0.0175\n",
      "Epoch 238/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 505.8568 - mean_squared_logarithmic_error: 0.0172\n",
      "Epoch 239/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 505.8356 - mean_squared_logarithmic_error: 0.0167\n",
      "Epoch 240/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 505.8265 - mean_squared_logarithmic_error: 0.0163\n",
      "Epoch 241/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 505.8170 - mean_squared_logarithmic_error: 0.0158\n",
      "Epoch 242/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 505.8311 - mean_squared_logarithmic_error: 0.0156\n",
      "Epoch 243/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 505.8111 - mean_squared_logarithmic_error: 0.0150\n",
      "Epoch 244/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 505.8135 - mean_squared_logarithmic_error: 0.0146\n",
      "Epoch 245/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 505.8084 - mean_squared_logarithmic_error: 0.0145\n",
      "Epoch 246/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 505.8063 - mean_squared_logarithmic_error: 0.0146\n",
      "Epoch 247/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 505.7678 - mean_squared_logarithmic_error: 0.0138\n",
      "Epoch 248/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 101us/sample - loss: 505.7786 - mean_squared_logarithmic_error: 0.0133\n",
      "Epoch 249/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 505.7497 - mean_squared_logarithmic_error: 0.0127\n",
      "Epoch 250/250\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 505.7501 - mean_squared_logarithmic_error: 0.0128\n"
     ]
    }
   ],
   "source": [
    "MultiplicationTraining = Training_Tensorflow(OutputVector='Multiplication')\n",
    "MultiplicationTraining.TrainTheModel(optimizer='adam',activation='selu',epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.21"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiplicationTraining.PredictOneVal(A=11,B=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little better but still far off. Let us try to increase the epochs to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 1s 167us/sample - loss: 1127.7993 - mean_squared_logarithmic_error: 3.9078\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1096.4977 - mean_squared_logarithmic_error: 3.5306\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1060.8051 - mean_squared_logarithmic_error: 3.5925\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1040.5694 - mean_squared_logarithmic_error: 3.6050\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1019.5138 - mean_squared_logarithmic_error: 3.4184\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 998.4669 - mean_squared_logarithmic_error: 3.1875\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 977.2303 - mean_squared_logarithmic_error: 2.8774\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 953.3617 - mean_squared_logarithmic_error: 2.5413\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 925.2576 - mean_squared_logarithmic_error: 2.2809\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 893.2177 - mean_squared_logarithmic_error: 2.0854\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 859.3224 - mean_squared_logarithmic_error: 1.9939\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 827.6621 - mean_squared_logarithmic_error: 1.9446\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 801.4265 - mean_squared_logarithmic_error: 1.9156\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 782.4775 - mean_squared_logarithmic_error: 1.8915\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 769.2514 - mean_squared_logarithmic_error: 1.8618\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 760.4936 - mean_squared_logarithmic_error: 1.8284\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 754.2169 - mean_squared_logarithmic_error: 1.8061\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 749.6024 - mean_squared_logarithmic_error: 1.7813\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 746.2250 - mean_squared_logarithmic_error: 1.7650\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 743.7627 - mean_squared_logarithmic_error: 1.7523\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 741.8121 - mean_squared_logarithmic_error: 1.7404\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 740.3606 - mean_squared_logarithmic_error: 1.7329\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 739.2050 - mean_squared_logarithmic_error: 1.7255\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 738.2588 - mean_squared_logarithmic_error: 1.7195\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 737.4695 - mean_squared_logarithmic_error: 1.7140\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 736.8846 - mean_squared_logarithmic_error: 1.7096\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 736.3888 - mean_squared_logarithmic_error: 1.7050\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 735.9852 - mean_squared_logarithmic_error: 1.7012\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 735.6904 - mean_squared_logarithmic_error: 1.6975\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 735.4237 - mean_squared_logarithmic_error: 1.6944\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 735.1633 - mean_squared_logarithmic_error: 1.6912\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 734.9739 - mean_squared_logarithmic_error: 1.6883\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 734.8080 - mean_squared_logarithmic_error: 1.6851\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 734.6716 - mean_squared_logarithmic_error: 1.6827\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 734.5693 - mean_squared_logarithmic_error: 1.6802\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 734.4579 - mean_squared_logarithmic_error: 1.6773\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 734.3688 - mean_squared_logarithmic_error: 1.6755\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 734.3009 - mean_squared_logarithmic_error: 1.6726\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 734.2347 - mean_squared_logarithmic_error: 1.6707\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 734.1715 - mean_squared_logarithmic_error: 1.6685\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 734.1168 - mean_squared_logarithmic_error: 1.6664\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 734.0728 - mean_squared_logarithmic_error: 1.6649\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 734.0302 - mean_squared_logarithmic_error: 1.6627\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 733.9919 - mean_squared_logarithmic_error: 1.6611\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 733.9584 - mean_squared_logarithmic_error: 1.6592\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 733.9281 - mean_squared_logarithmic_error: 1.6573\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.8905 - mean_squared_logarithmic_error: 1.6559\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 733.8855 - mean_squared_logarithmic_error: 1.6545\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.8463 - mean_squared_logarithmic_error: 1.6528\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 733.8273 - mean_squared_logarithmic_error: 1.6513\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 733.8079 - mean_squared_logarithmic_error: 1.6500\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 733.7860 - mean_squared_logarithmic_error: 1.6493\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 733.7631 - mean_squared_logarithmic_error: 1.6479\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 733.7606 - mean_squared_logarithmic_error: 1.6455\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 733.7397 - mean_squared_logarithmic_error: 1.6454\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 733.7197 - mean_squared_logarithmic_error: 1.6447\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 733.7073 - mean_squared_logarithmic_error: 1.6433\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 733.6961 - mean_squared_logarithmic_error: 1.6425\n",
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 733.6857 - mean_squared_logarithmic_error: 1.6418s - loss: 750.5983 - mean_squared_log\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 733.6879 - mean_squared_logarithmic_error: 1.6404\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 733.6537 - mean_squared_logarithmic_error: 1.6401\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 121us/sample - loss: 733.6600 - mean_squared_logarithmic_error: 1.6390\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 733.6607 - mean_squared_logarithmic_error: 1.6386\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 733.6230 - mean_squared_logarithmic_error: 1.6378\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 733.6099 - mean_squared_logarithmic_error: 1.6371\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.6034 - mean_squared_logarithmic_error: 1.6363\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 733.6017 - mean_squared_logarithmic_error: 1.6362\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 733.6191 - mean_squared_logarithmic_error: 1.6361\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 733.5727 - mean_squared_logarithmic_error: 1.6352\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 733.5749 - mean_squared_logarithmic_error: 1.6354\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 733.5628 - mean_squared_logarithmic_error: 1.6341\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 733.5377 - mean_squared_logarithmic_error: 1.6335\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.5397 - mean_squared_logarithmic_error: 1.6330\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 733.5265 - mean_squared_logarithmic_error: 1.6326\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 733.5214 - mean_squared_logarithmic_error: 1.6325\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 733.5193 - mean_squared_logarithmic_error: 1.6323\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 733.5019 - mean_squared_logarithmic_error: 1.6313\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 733.5090 - mean_squared_logarithmic_error: 1.6321\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 733.4818 - mean_squared_logarithmic_error: 1.6313\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 733.4818 - mean_squared_logarithmic_error: 1.6298\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 733.4733 - mean_squared_logarithmic_error: 1.6300\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 733.4597 - mean_squared_logarithmic_error: 1.6299\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.4744 - mean_squared_logarithmic_error: 1.6295\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 733.4559 - mean_squared_logarithmic_error: 1.6286\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 733.3897 - mean_squared_logarithmic_error: 1.6286\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 733.1618 - mean_squared_logarithmic_error: 1.6262\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 733.0478 - mean_squared_logarithmic_error: 1.6255\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 732.8155 - mean_squared_logarithmic_error: 1.6238\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 732.5161 - mean_squared_logarithmic_error: 1.6213\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 731.9616 - mean_squared_logarithmic_error: 1.6161\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 730.7184 - mean_squared_logarithmic_error: 1.6068\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 1s 131us/sample - loss: 722.9957 - mean_squared_logarithmic_error: 1.5435\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 672.9216 - mean_squared_logarithmic_error: 1.1727\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 660.7690 - mean_squared_logarithmic_error: 1.1069\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 659.0137 - mean_squared_logarithmic_error: 1.1034\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 658.7309 - mean_squared_logarithmic_error: 1.0964\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 658.5911 - mean_squared_logarithmic_error: 1.0967\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 658.5554 - mean_squared_logarithmic_error: 1.0943\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 658.5335 - mean_squared_logarithmic_error: 1.0936\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 658.4789 - mean_squared_logarithmic_error: 1.0926\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 658.4669 - mean_squared_logarithmic_error: 1.0920\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 658.4513 - mean_squared_logarithmic_error: 1.0911\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 658.4524 - mean_squared_logarithmic_error: 1.0908\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 658.4183 - mean_squared_logarithmic_error: 1.0906\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 658.4057 - mean_squared_logarithmic_error: 1.0894\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 1s 130us/sample - loss: 658.3877 - mean_squared_logarithmic_error: 1.0892\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 658.3790 - mean_squared_logarithmic_error: 1.0894\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 658.3778 - mean_squared_logarithmic_error: 1.0876\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 658.3560 - mean_squared_logarithmic_error: 1.0870\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 658.3482 - mean_squared_logarithmic_error: 1.0867\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 658.3168 - mean_squared_logarithmic_error: 1.0857\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 658.3193 - mean_squared_logarithmic_error: 1.0852\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 658.2901 - mean_squared_logarithmic_error: 1.0852\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 658.2673 - mean_squared_logarithmic_error: 1.0845\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 658.2689 - mean_squared_logarithmic_error: 1.0843\n",
      "Epoch 116/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 658.2545 - mean_squared_logarithmic_error: 1.0828\n",
      "Epoch 117/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 658.2946 - mean_squared_logarithmic_error: 1.0828\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 658.2153 - mean_squared_logarithmic_error: 1.0816\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 658.1959 - mean_squared_logarithmic_error: 1.0818\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 658.1961 - mean_squared_logarithmic_error: 1.0807\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 658.1923 - mean_squared_logarithmic_error: 1.0810\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 658.1666 - mean_squared_logarithmic_error: 1.0784\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 112us/sample - loss: 658.1323 - mean_squared_logarithmic_error: 1.0791\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 658.1140 - mean_squared_logarithmic_error: 1.0775\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 658.0956 - mean_squared_logarithmic_error: 1.0773\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 1s 138us/sample - loss: 658.0974 - mean_squared_logarithmic_error: 1.0766\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 658.0694 - mean_squared_logarithmic_error: 1.0752\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 658.0453 - mean_squared_logarithmic_error: 1.0750\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 658.0330 - mean_squared_logarithmic_error: 1.0746\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 658.0300 - mean_squared_logarithmic_error: 1.0728\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 658.0262 - mean_squared_logarithmic_error: 1.0726\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 657.9992 - mean_squared_logarithmic_error: 1.0713\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 657.9590 - mean_squared_logarithmic_error: 1.0704\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 657.9156 - mean_squared_logarithmic_error: 1.0695\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 657.9114 - mean_squared_logarithmic_error: 1.0688\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 657.8880 - mean_squared_logarithmic_error: 1.0678\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 657.8611 - mean_squared_logarithmic_error: 1.0666\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 657.8340 - mean_squared_logarithmic_error: 1.0662\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 657.8503 - mean_squared_logarithmic_error: 1.0654\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 657.7999 - mean_squared_logarithmic_error: 1.0632\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 657.7836 - mean_squared_logarithmic_error: 1.0637\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 657.7506 - mean_squared_logarithmic_error: 1.0620\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 657.6122 - mean_squared_logarithmic_error: 1.0606\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 657.4029 - mean_squared_logarithmic_error: 1.0586\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 657.2355 - mean_squared_logarithmic_error: 1.0569\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 657.0707 - mean_squared_logarithmic_error: 1.0543\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 656.6884 - mean_squared_logarithmic_error: 1.0518\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 655.6510 - mean_squared_logarithmic_error: 1.0438\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 653.5979 - mean_squared_logarithmic_error: 1.0274\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 585.2347 - mean_squared_logarithmic_error: 0.5031\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 529.3678 - mean_squared_logarithmic_error: 0.1128\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 523.8479 - mean_squared_logarithmic_error: 0.0721\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 522.9854 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 522.6911 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 522.6544 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 522.6270 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 522.5270 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 522.4955 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 522.4639 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 522.4392 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 522.4213 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 522.3911 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 522.3688 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 522.3799 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 522.3244 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 522.2908 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 522.3032 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 522.2957 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 522.2430 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 522.2225 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 522.1993 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 522.1988 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 173/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 522.1681 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 522.1352 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 522.1258 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 522.1038 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 522.1170 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 522.1063 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 522.0771 - mean_squared_logarithmic_error: 0.0536\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 522.0591 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 181/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 522.0221 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 522.0223 - mean_squared_logarithmic_error: 0.0534\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 522.0478 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 96us/sample - loss: 522.0104 - mean_squared_logarithmic_error: 0.0530\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.9639 - mean_squared_logarithmic_error: 0.0529\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 521.9653 - mean_squared_logarithmic_error: 0.0527\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 521.9419 - mean_squared_logarithmic_error: 0.0523\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 521.9356 - mean_squared_logarithmic_error: 0.0518\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 521.9075 - mean_squared_logarithmic_error: 0.0514\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.8852 - mean_squared_logarithmic_error: 0.0517\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.8852 - mean_squared_logarithmic_error: 0.0511\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 521.8763 - mean_squared_logarithmic_error: 0.0511\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 521.8587 - mean_squared_logarithmic_error: 0.0508\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.8413 - mean_squared_logarithmic_error: 0.0501\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 521.8267 - mean_squared_logarithmic_error: 0.0502\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 521.8087 - mean_squared_logarithmic_error: 0.0496\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.8259 - mean_squared_logarithmic_error: 0.0496\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 521.8228 - mean_squared_logarithmic_error: 0.0487\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 521.7728 - mean_squared_logarithmic_error: 0.0485\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 521.7508 - mean_squared_logarithmic_error: 0.0481\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.7350 - mean_squared_logarithmic_error: 0.0475\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.7362 - mean_squared_logarithmic_error: 0.0474\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 521.7110 - mean_squared_logarithmic_error: 0.0469\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 521.6967 - mean_squared_logarithmic_error: 0.0463\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 521.7028 - mean_squared_logarithmic_error: 0.0464\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 521.6792 - mean_squared_logarithmic_error: 0.0454\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 521.7071 - mean_squared_logarithmic_error: 0.0456\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 521.6597 - mean_squared_logarithmic_error: 0.0453\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.6739 - mean_squared_logarithmic_error: 0.0443\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.6246 - mean_squared_logarithmic_error: 0.0435\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.6032 - mean_squared_logarithmic_error: 0.0427\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 521.6097 - mean_squared_logarithmic_error: 0.0428\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 521.6115 - mean_squared_logarithmic_error: 0.0427\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 521.6015 - mean_squared_logarithmic_error: 0.0412\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 521.5910 - mean_squared_logarithmic_error: 0.0415\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.5487 - mean_squared_logarithmic_error: 0.0406\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 521.5331 - mean_squared_logarithmic_error: 0.0404\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.5274 - mean_squared_logarithmic_error: 0.0397\n",
      "Epoch 219/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.5314 - mean_squared_logarithmic_error: 0.0390\n",
      "Epoch 220/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 521.5017 - mean_squared_logarithmic_error: 0.0385\n",
      "Epoch 221/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.4838 - mean_squared_logarithmic_error: 0.0379\n",
      "Epoch 222/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.4809 - mean_squared_logarithmic_error: 0.0377\n",
      "Epoch 223/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 521.4783 - mean_squared_logarithmic_error: 0.0366\n",
      "Epoch 224/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.5016 - mean_squared_logarithmic_error: 0.0366\n",
      "Epoch 225/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.4517 - mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 226/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 521.4333 - mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 227/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 521.4228 - mean_squared_logarithmic_error: 0.0346\n",
      "Epoch 228/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 521.4198 - mean_squared_logarithmic_error: 0.0340\n",
      "Epoch 229/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.3894 - mean_squared_logarithmic_error: 0.0331\n",
      "Epoch 230/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 521.3873 - mean_squared_logarithmic_error: 0.0327\n",
      "Epoch 231/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.3793 - mean_squared_logarithmic_error: 0.0324\n",
      "Epoch 232/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 521.3754 - mean_squared_logarithmic_error: 0.0315\n",
      "Epoch 233/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 521.3470 - mean_squared_logarithmic_error: 0.0309\n",
      "Epoch 234/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 521.3287 - mean_squared_logarithmic_error: 0.0302\n",
      "Epoch 235/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 521.3209 - mean_squared_logarithmic_error: 0.0298\n",
      "Epoch 236/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.3224 - mean_squared_logarithmic_error: 0.0293\n",
      "Epoch 237/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.3304 - mean_squared_logarithmic_error: 0.0287\n",
      "Epoch 238/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.3270 - mean_squared_logarithmic_error: 0.0289\n",
      "Epoch 239/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.2808 - mean_squared_logarithmic_error: 0.0279\n",
      "Epoch 240/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 521.2603 - mean_squared_logarithmic_error: 0.0270\n",
      "Epoch 241/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 521.2529 - mean_squared_logarithmic_error: 0.0265\n",
      "Epoch 242/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.2498 - mean_squared_logarithmic_error: 0.0260\n",
      "Epoch 243/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 521.2297 - mean_squared_logarithmic_error: 0.0254\n",
      "Epoch 244/1000\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 521.2317 - mean_squared_logarithmic_error: 0.0248\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.2302 - mean_squared_logarithmic_error: 0.0242\n",
      "Epoch 246/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 521.2457 - mean_squared_logarithmic_error: 0.0243\n",
      "Epoch 247/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.1913 - mean_squared_logarithmic_error: 0.0231\n",
      "Epoch 248/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 521.1885 - mean_squared_logarithmic_error: 0.0227\n",
      "Epoch 249/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 521.1707 - mean_squared_logarithmic_error: 0.0223\n",
      "Epoch 250/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 521.1733 - mean_squared_logarithmic_error: 0.0218\n",
      "Epoch 251/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.1648 - mean_squared_logarithmic_error: 0.0212\n",
      "Epoch 252/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 521.1391 - mean_squared_logarithmic_error: 0.0207\n",
      "Epoch 253/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.1436 - mean_squared_logarithmic_error: 0.0202\n",
      "Epoch 254/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.1273 - mean_squared_logarithmic_error: 0.0199\n",
      "Epoch 255/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 521.1219 - mean_squared_logarithmic_error: 0.0192\n",
      "Epoch 256/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.1044 - mean_squared_logarithmic_error: 0.0188\n",
      "Epoch 257/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.0971 - mean_squared_logarithmic_error: 0.0183\n",
      "Epoch 258/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 521.1018 - mean_squared_logarithmic_error: 0.0177\n",
      "Epoch 259/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 521.0740 - mean_squared_logarithmic_error: 0.0172\n",
      "Epoch 260/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 521.0691 - mean_squared_logarithmic_error: 0.0168\n",
      "Epoch 261/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 521.0565 - mean_squared_logarithmic_error: 0.0165\n",
      "Epoch 262/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 521.0638 - mean_squared_logarithmic_error: 0.0160\n",
      "Epoch 263/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 521.0423 - mean_squared_logarithmic_error: 0.0155\n",
      "Epoch 264/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 521.0422 - mean_squared_logarithmic_error: 0.0154\n",
      "Epoch 265/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 521.0233 - mean_squared_logarithmic_error: 0.0146\n",
      "Epoch 266/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 521.0128 - mean_squared_logarithmic_error: 0.0142\n",
      "Epoch 267/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 521.0065 - mean_squared_logarithmic_error: 0.0139\n",
      "Epoch 268/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 521.0071 - mean_squared_logarithmic_error: 0.0138\n",
      "Epoch 269/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.9996 - mean_squared_logarithmic_error: 0.0133\n",
      "Epoch 270/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.9968 - mean_squared_logarithmic_error: 0.0130\n",
      "Epoch 271/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.9915 - mean_squared_logarithmic_error: 0.0125\n",
      "Epoch 272/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.9726 - mean_squared_logarithmic_error: 0.0119\n",
      "Epoch 273/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.9621 - mean_squared_logarithmic_error: 0.0116\n",
      "Epoch 274/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.9627 - mean_squared_logarithmic_error: 0.0115\n",
      "Epoch 275/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.9472 - mean_squared_logarithmic_error: 0.0109\n",
      "Epoch 276/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.9448 - mean_squared_logarithmic_error: 0.0106\n",
      "Epoch 277/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.9567 - mean_squared_logarithmic_error: 0.0105\n",
      "Epoch 278/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.9289 - mean_squared_logarithmic_error: 0.0100\n",
      "Epoch 279/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.9409 - mean_squared_logarithmic_error: 0.0100\n",
      "Epoch 280/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.9251 - mean_squared_logarithmic_error: 0.0095\n",
      "Epoch 281/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.9307 - mean_squared_logarithmic_error: 0.0095\n",
      "Epoch 282/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.9533 - mean_squared_logarithmic_error: 0.0096\n",
      "Epoch 283/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.9236 - mean_squared_logarithmic_error: 0.0089\n",
      "Epoch 284/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.9011 - mean_squared_logarithmic_error: 0.0086\n",
      "Epoch 285/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.9125 - mean_squared_logarithmic_error: 0.0084\n",
      "Epoch 286/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.9051 - mean_squared_logarithmic_error: 0.0080\n",
      "Epoch 287/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.8981 - mean_squared_logarithmic_error: 0.0079\n",
      "Epoch 288/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.8949 - mean_squared_logarithmic_error: 0.0077\n",
      "Epoch 289/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.8789 - mean_squared_logarithmic_error: 0.0074\n",
      "Epoch 290/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.8743 - mean_squared_logarithmic_error: 0.0073\n",
      "Epoch 291/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.8663 - mean_squared_logarithmic_error: 0.0070\n",
      "Epoch 292/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.8826 - mean_squared_logarithmic_error: 0.0071\n",
      "Epoch 293/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.8599 - mean_squared_logarithmic_error: 0.0066\n",
      "Epoch 294/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.8464 - mean_squared_logarithmic_error: 0.0065\n",
      "Epoch 295/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.8544 - mean_squared_logarithmic_error: 0.0062\n",
      "Epoch 296/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.8740 - mean_squared_logarithmic_error: 0.0063\n",
      "Epoch 297/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.8632 - mean_squared_logarithmic_error: 0.0060\n",
      "Epoch 298/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.8534 - mean_squared_logarithmic_error: 0.0062\n",
      "Epoch 299/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.8402 - mean_squared_logarithmic_error: 0.0058\n",
      "Epoch 300/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.8253 - mean_squared_logarithmic_error: 0.0053\n",
      "Epoch 301/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.8261 - mean_squared_logarithmic_error: 0.0055\n",
      "Epoch 302/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.8134 - mean_squared_logarithmic_error: 0.0051\n",
      "Epoch 303/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.8137 - mean_squared_logarithmic_error: 0.0053\n",
      "Epoch 304/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.8118 - mean_squared_logarithmic_error: 0.0050\n",
      "Epoch 305/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.8090 - mean_squared_logarithmic_error: 0.0051\n",
      "Epoch 306/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.8158 - mean_squared_logarithmic_error: 0.0049\n",
      "Epoch 307/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.8090 - mean_squared_logarithmic_error: 0.0049\n",
      "Epoch 308/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.7946 - mean_squared_logarithmic_error: 0.0046\n",
      "Epoch 309/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.7999 - mean_squared_logarithmic_error: 0.0045\n",
      "Epoch 310/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.7891 - mean_squared_logarithmic_error: 0.0045\n",
      "Epoch 311/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.7954 - mean_squared_logarithmic_error: 0.0046\n",
      "Epoch 312/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.7886 - mean_squared_logarithmic_error: 0.0044\n",
      "Epoch 313/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.7809 - mean_squared_logarithmic_error: 0.0041\n",
      "Epoch 314/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.7800 - mean_squared_logarithmic_error: 0.0041\n",
      "Epoch 315/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.7760 - mean_squared_logarithmic_error: 0.0041\n",
      "Epoch 316/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.7688 - mean_squared_logarithmic_error: 0.0040\n",
      "Epoch 317/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7697 - mean_squared_logarithmic_error: 0.0040\n",
      "Epoch 318/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7619 - mean_squared_logarithmic_error: 0.0040\n",
      "Epoch 319/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7605 - mean_squared_logarithmic_error: 0.0037\n",
      "Epoch 320/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.7579 - mean_squared_logarithmic_error: 0.0038\n",
      "Epoch 321/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7552 - mean_squared_logarithmic_error: 0.0036\n",
      "Epoch 322/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.7542 - mean_squared_logarithmic_error: 0.0037\n",
      "Epoch 323/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.7576 - mean_squared_logarithmic_error: 0.0037\n",
      "Epoch 324/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.7642 - mean_squared_logarithmic_error: 0.0036\n",
      "Epoch 325/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.7622 - mean_squared_logarithmic_error: 0.0036\n",
      "Epoch 326/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.7588 - mean_squared_logarithmic_error: 0.0037\n",
      "Epoch 327/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.7639 - mean_squared_logarithmic_error: 0.0036\n",
      "Epoch 328/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.7447 - mean_squared_logarithmic_error: 0.0036\n",
      "Epoch 329/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.7438 - mean_squared_logarithmic_error: 0.0034\n",
      "Epoch 330/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7389 - mean_squared_logarithmic_error: 0.0033\n",
      "Epoch 331/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.7335 - mean_squared_logarithmic_error: 0.0033\n",
      "Epoch 332/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7374 - mean_squared_logarithmic_error: 0.0032\n",
      "Epoch 333/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.7296 - mean_squared_logarithmic_error: 0.0031\n",
      "Epoch 334/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7340 - mean_squared_logarithmic_error: 0.0033\n",
      "Epoch 335/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7292 - mean_squared_logarithmic_error: 0.0031\n",
      "Epoch 336/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7247 - mean_squared_logarithmic_error: 0.0031\n",
      "Epoch 337/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.7266 - mean_squared_logarithmic_error: 0.0031\n",
      "Epoch 338/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.7264 - mean_squared_logarithmic_error: 0.0030\n",
      "Epoch 339/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.7194 - mean_squared_logarithmic_error: 0.0030\n",
      "Epoch 340/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.7161 - mean_squared_logarithmic_error: 0.0029\n",
      "Epoch 341/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7119 - mean_squared_logarithmic_error: 0.0029\n",
      "Epoch 342/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.7178 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 343/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.7295 - mean_squared_logarithmic_error: 0.0030\n",
      "Epoch 344/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.7138 - mean_squared_logarithmic_error: 0.0027\n",
      "Epoch 345/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.7073 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 346/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.7201 - mean_squared_logarithmic_error: 0.0029\n",
      "Epoch 347/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.7127 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 348/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.7069 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 349/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.7037 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 350/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.7048 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 351/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.7065 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 352/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.7164 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 353/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.7031 - mean_squared_logarithmic_error: 0.0025\n",
      "Epoch 354/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.7075 - mean_squared_logarithmic_error: 0.0028\n",
      "Epoch 355/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6986 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 356/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6963 - mean_squared_logarithmic_error: 0.0024\n",
      "Epoch 357/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6925 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 358/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.6962 - mean_squared_logarithmic_error: 0.0025\n",
      "Epoch 359/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.7043 - mean_squared_logarithmic_error: 0.0026\n",
      "Epoch 360/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6879 - mean_squared_logarithmic_error: 0.0023\n",
      "Epoch 361/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6862 - mean_squared_logarithmic_error: 0.0024\n",
      "Epoch 362/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6853 - mean_squared_logarithmic_error: 0.0024\n",
      "Epoch 363/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6852 - mean_squared_logarithmic_error: 0.0024\n",
      "Epoch 364/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6871 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 365/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6797 - mean_squared_logarithmic_error: 0.0023\n",
      "Epoch 366/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6794 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6831 - mean_squared_logarithmic_error: 0.0023\n",
      "Epoch 368/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.6826 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 369/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6830 - mean_squared_logarithmic_error: 0.0023\n",
      "Epoch 370/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6813 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 371/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.6730 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 372/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.6872 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 373/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6769 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 374/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 520.6709 - mean_squared_logarithmic_error: 0.0021\n",
      "Epoch 375/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.6769 - mean_squared_logarithmic_error: 0.0021\n",
      "Epoch 376/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6751 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 377/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.6731 - mean_squared_logarithmic_error: 0.0020\n",
      "Epoch 378/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6720 - mean_squared_logarithmic_error: 0.0020\n",
      "Epoch 379/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6711 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 380/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6765 - mean_squared_logarithmic_error: 0.0021\n",
      "Epoch 381/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6624 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 382/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.6764 - mean_squared_logarithmic_error: 0.0022\n",
      "Epoch 383/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6729 - mean_squared_logarithmic_error: 0.0020\n",
      "Epoch 384/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6707 - mean_squared_logarithmic_error: 0.0020\n",
      "Epoch 385/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6638 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 386/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6622 - mean_squared_logarithmic_error: 0.0020\n",
      "Epoch 387/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6592 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 388/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6582 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 389/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6576 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 390/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6575 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 391/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.6638 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 392/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6576 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 393/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.6524 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 394/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6552 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 395/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6533 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 396/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6507 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 397/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6481 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 398/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6489 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 399/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6557 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 400/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6512 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 401/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.6569 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 402/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6456 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 403/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6512 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 404/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6654 - mean_squared_logarithmic_error: 0.0019\n",
      "Epoch 405/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6613 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 406/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6585 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 407/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6495 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 408/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6464 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 409/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6527 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 410/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6579 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 411/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6531 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 412/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6523 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 413/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6449 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 414/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.6579 - mean_squared_logarithmic_error: 0.0017\n",
      "Epoch 415/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6648 - mean_squared_logarithmic_error: 0.0018\n",
      "Epoch 416/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6413 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 417/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6407 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 418/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6371 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 419/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6359 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 420/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6345 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 421/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6309 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 422/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6334 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 423/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6304 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 424/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.6315 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 425/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6379 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 426/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.6300 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 427/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 520.6273 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 428/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6277 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 429/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6351 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 430/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6420 - mean_squared_logarithmic_error: 0.0016\n",
      "Epoch 431/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.6319 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 432/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6313 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 433/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.6379 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 434/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6337 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 435/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.6268 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 436/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6289 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 437/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.6396 - mean_squared_logarithmic_error: 0.0015\n",
      "Epoch 438/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6260 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 439/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.6254 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 440/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.6281 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 441/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6250 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 442/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6241 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 443/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.6255 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 444/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.6272 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 445/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.6235 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 446/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.6218 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 447/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.6234 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 448/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.6235 - mean_squared_logarithmic_error: 0.0014\n",
      "Epoch 449/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.6236 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 450/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6174 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 451/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6190 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 452/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.6251 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 453/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.6184 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 454/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.6160 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 455/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.6239 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 456/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6230 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 457/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.6169 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 458/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6151 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 459/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.6145 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 460/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6161 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 461/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6159 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 462/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6159 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 463/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6136 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 464/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6119 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 465/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6148 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 466/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6160 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 467/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6163 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 468/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6132 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 469/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6101 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 470/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.6115 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 471/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.6182 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 472/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.6139 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 473/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6172 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 474/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.6231 - mean_squared_logarithmic_error: 0.0013\n",
      "Epoch 475/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6133 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 476/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6095 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 477/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6120 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 478/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6147 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 479/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6143 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 480/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.6106 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 481/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6103 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 482/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6120 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 483/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6191 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 484/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.6151 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 485/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.6067 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 486/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.6056 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 487/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6082 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 488/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.6108 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6104 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 490/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6162 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 491/1000\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 520.6104 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 492/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6029 - mean_squared_logarithmic_error: 9.6839e-04\n",
      "Epoch 493/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6090 - mean_squared_logarithmic_error: 9.8048e-04\n",
      "Epoch 494/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6205 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 495/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6081 - mean_squared_logarithmic_error: 9.9687e-04\n",
      "Epoch 496/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.6179 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 497/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.6088 - mean_squared_logarithmic_error: 0.0011\n",
      "Epoch 498/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.6067 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 499/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6064 - mean_squared_logarithmic_error: 9.6583e-04\n",
      "Epoch 500/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6008 - mean_squared_logarithmic_error: 9.2549e-04\n",
      "Epoch 501/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.6029 - mean_squared_logarithmic_error: 9.3024e-04\n",
      "Epoch 502/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6016 - mean_squared_logarithmic_error: 9.6810e-04\n",
      "Epoch 503/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.6011 - mean_squared_logarithmic_error: 9.0659e-04\n",
      "Epoch 504/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5994 - mean_squared_logarithmic_error: 8.8549e-04\n",
      "Epoch 505/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6016 - mean_squared_logarithmic_error: 8.9315e-04\n",
      "Epoch 506/1000\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 520.6001 - mean_squared_logarithmic_error: 9.4174e-04\n",
      "Epoch 507/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6076 - mean_squared_logarithmic_error: 9.9378e-04\n",
      "Epoch 508/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6152 - mean_squared_logarithmic_error: 0.0012\n",
      "Epoch 509/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6037 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 510/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.6041 - mean_squared_logarithmic_error: 9.8030e-04\n",
      "Epoch 511/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5998 - mean_squared_logarithmic_error: 8.8418e-04\n",
      "Epoch 512/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5989 - mean_squared_logarithmic_error: 9.0330e-04\n",
      "Epoch 513/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.6024 - mean_squared_logarithmic_error: 9.4955e-04\n",
      "Epoch 514/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5986 - mean_squared_logarithmic_error: 8.5996e-04\n",
      "Epoch 515/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.6007 - mean_squared_logarithmic_error: 9.3423e-04\n",
      "Epoch 516/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5998 - mean_squared_logarithmic_error: 8.7681e-04\n",
      "Epoch 517/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5994 - mean_squared_logarithmic_error: 9.6661e-04\n",
      "Epoch 518/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.6009 - mean_squared_logarithmic_error: 9.2730e-04\n",
      "Epoch 519/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5956 - mean_squared_logarithmic_error: 8.3116e-04\n",
      "Epoch 520/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6036 - mean_squared_logarithmic_error: 9.1253e-04\n",
      "Epoch 521/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.6007 - mean_squared_logarithmic_error: 8.6864e-04\n",
      "Epoch 522/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6010 - mean_squared_logarithmic_error: 9.3657e-04\n",
      "Epoch 523/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6021 - mean_squared_logarithmic_error: 8.9293e-04\n",
      "Epoch 524/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5993 - mean_squared_logarithmic_error: 9.1514e-04\n",
      "Epoch 525/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6011 - mean_squared_logarithmic_error: 8.9564e-04\n",
      "Epoch 526/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5968 - mean_squared_logarithmic_error: 8.3521e-04\n",
      "Epoch 527/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5957 - mean_squared_logarithmic_error: 8.3894e-04\n",
      "Epoch 528/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5965 - mean_squared_logarithmic_error: 8.4419e-04\n",
      "Epoch 529/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5972 - mean_squared_logarithmic_error: 8.0966e-04\n",
      "Epoch 530/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5941 - mean_squared_logarithmic_error: 8.1992e-04\n",
      "Epoch 531/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5978 - mean_squared_logarithmic_error: 8.2979e-04\n",
      "Epoch 532/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5950 - mean_squared_logarithmic_error: 8.1767e-04\n",
      "Epoch 533/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.6017 - mean_squared_logarithmic_error: 9.3169e-04\n",
      "Epoch 534/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6080 - mean_squared_logarithmic_error: 9.6558e-04\n",
      "Epoch 535/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.6087 - mean_squared_logarithmic_error: 0.0010\n",
      "Epoch 536/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5989 - mean_squared_logarithmic_error: 8.7212e-04\n",
      "Epoch 537/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5949 - mean_squared_logarithmic_error: 7.6482e-04\n",
      "Epoch 538/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5944 - mean_squared_logarithmic_error: 8.4078e-04\n",
      "Epoch 539/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5936 - mean_squared_logarithmic_error: 8.3504e-04\n",
      "Epoch 540/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5955 - mean_squared_logarithmic_error: 7.6119e-04\n",
      "Epoch 541/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5959 - mean_squared_logarithmic_error: 8.2801e-04\n",
      "Epoch 542/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 520.5936 - mean_squared_logarithmic_error: 7.9769e-04\n",
      "Epoch 543/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5944 - mean_squared_logarithmic_error: 7.8023e-04\n",
      "Epoch 544/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5918 - mean_squared_logarithmic_error: 7.5914e-04\n",
      "Epoch 545/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5964 - mean_squared_logarithmic_error: 7.8476e-04\n",
      "Epoch 546/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5967 - mean_squared_logarithmic_error: 8.3863e-04\n",
      "Epoch 547/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5981 - mean_squared_logarithmic_error: 8.2912e-04\n",
      "Epoch 548/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5929 - mean_squared_logarithmic_error: 7.8741e-04\n",
      "Epoch 549/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5909 - mean_squared_logarithmic_error: 7.6696e-04\n",
      "Epoch 550/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5956 - mean_squared_logarithmic_error: 7.6690e-04\n",
      "Epoch 551/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5966 - mean_squared_logarithmic_error: 8.2748e-04\n",
      "Epoch 552/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5957 - mean_squared_logarithmic_error: 7.9926e-04\n",
      "Epoch 553/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5950 - mean_squared_logarithmic_error: 7.5063e-04\n",
      "Epoch 554/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5915 - mean_squared_logarithmic_error: 7.2566e-04\n",
      "Epoch 555/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5932 - mean_squared_logarithmic_error: 7.2727e-04\n",
      "Epoch 556/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5910 - mean_squared_logarithmic_error: 7.8426e-04\n",
      "Epoch 557/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.6102 - mean_squared_logarithmic_error: 9.3322e-04\n",
      "Epoch 558/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.6013 - mean_squared_logarithmic_error: 8.6584e-04\n",
      "Epoch 559/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5918 - mean_squared_logarithmic_error: 7.3807e-04\n",
      "Epoch 560/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5966 - mean_squared_logarithmic_error: 7.7860e-04\n",
      "Epoch 561/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5935 - mean_squared_logarithmic_error: 7.3987e-04\n",
      "Epoch 562/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5980 - mean_squared_logarithmic_error: 7.8142e-04\n",
      "Epoch 563/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5998 - mean_squared_logarithmic_error: 7.5884e-04\n",
      "Epoch 564/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5893 - mean_squared_logarithmic_error: 6.5623e-04\n",
      "Epoch 565/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5912 - mean_squared_logarithmic_error: 7.3305e-04\n",
      "Epoch 566/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5931 - mean_squared_logarithmic_error: 7.5754e-04\n",
      "Epoch 567/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5912 - mean_squared_logarithmic_error: 7.2677e-04\n",
      "Epoch 568/1000\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 520.5881 - mean_squared_logarithmic_error: 7.0042e-04\n",
      "Epoch 569/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6006 - mean_squared_logarithmic_error: 8.8013e-04\n",
      "Epoch 570/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.6005 - mean_squared_logarithmic_error: 8.0474e-04\n",
      "Epoch 571/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5977 - mean_squared_logarithmic_error: 8.2692e-04\n",
      "Epoch 572/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5895 - mean_squared_logarithmic_error: 7.5172e-04\n",
      "Epoch 573/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5888 - mean_squared_logarithmic_error: 6.5239e-04\n",
      "Epoch 574/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 520.5878 - mean_squared_logarithmic_error: 6.5374e-04\n",
      "Epoch 575/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5884 - mean_squared_logarithmic_error: 6.9780e-04\n",
      "Epoch 576/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5917 - mean_squared_logarithmic_error: 7.1678e-04\n",
      "Epoch 577/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5897 - mean_squared_logarithmic_error: 6.9587e-04\n",
      "Epoch 578/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5945 - mean_squared_logarithmic_error: 7.2772e-04\n",
      "Epoch 579/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5912 - mean_squared_logarithmic_error: 7.0772e-04\n",
      "Epoch 580/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5877 - mean_squared_logarithmic_error: 6.7068e-04\n",
      "Epoch 581/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5949 - mean_squared_logarithmic_error: 7.4042e-04\n",
      "Epoch 582/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5883 - mean_squared_logarithmic_error: 6.5795e-04\n",
      "Epoch 583/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5979 - mean_squared_logarithmic_error: 7.8062e-04\n",
      "Epoch 584/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5968 - mean_squared_logarithmic_error: 7.7986e-04\n",
      "Epoch 585/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5907 - mean_squared_logarithmic_error: 6.5366e-04\n",
      "Epoch 586/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5928 - mean_squared_logarithmic_error: 7.5516e-04\n",
      "Epoch 587/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5942 - mean_squared_logarithmic_error: 7.7292e-04\n",
      "Epoch 588/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5982 - mean_squared_logarithmic_error: 7.7213e-04\n",
      "Epoch 589/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5858 - mean_squared_logarithmic_error: 6.1247e-04\n",
      "Epoch 590/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5876 - mean_squared_logarithmic_error: 6.5893e-04\n",
      "Epoch 591/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5862 - mean_squared_logarithmic_error: 6.6633e-04\n",
      "Epoch 592/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5860 - mean_squared_logarithmic_error: 6.3363e-04\n",
      "Epoch 593/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5882 - mean_squared_logarithmic_error: 6.1308e-04\n",
      "Epoch 594/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5855 - mean_squared_logarithmic_error: 6.0678e-04\n",
      "Epoch 595/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5885 - mean_squared_logarithmic_error: 6.8423e-04\n",
      "Epoch 596/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5894 - mean_squared_logarithmic_error: 6.8689e-04\n",
      "Epoch 597/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5914 - mean_squared_logarithmic_error: 6.9558e-04\n",
      "Epoch 598/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5955 - mean_squared_logarithmic_error: 7.8086e-04\n",
      "Epoch 599/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5889 - mean_squared_logarithmic_error: 6.5465e-04\n",
      "Epoch 600/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5917 - mean_squared_logarithmic_error: 6.7827e-04\n",
      "Epoch 601/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5863 - mean_squared_logarithmic_error: 6.5401e-04\n",
      "Epoch 602/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5884 - mean_squared_logarithmic_error: 6.4814e-04\n",
      "Epoch 603/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5909 - mean_squared_logarithmic_error: 6.8431e-04\n",
      "Epoch 604/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5848 - mean_squared_logarithmic_error: 6.2938e-04\n",
      "Epoch 605/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5851 - mean_squared_logarithmic_error: 5.9210e-04\n",
      "Epoch 606/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5959 - mean_squared_logarithmic_error: 7.0764e-04\n",
      "Epoch 607/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5883 - mean_squared_logarithmic_error: 6.5477e-04\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5984 - mean_squared_logarithmic_error: 6.9919e-04\n",
      "Epoch 609/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5972 - mean_squared_logarithmic_error: 7.0192e-04\n",
      "Epoch 610/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5880 - mean_squared_logarithmic_error: 6.0138e-04\n",
      "Epoch 611/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5933 - mean_squared_logarithmic_error: 7.3850e-04\n",
      "Epoch 612/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5958 - mean_squared_logarithmic_error: 7.2452e-04\n",
      "Epoch 613/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5836 - mean_squared_logarithmic_error: 5.8086e-04\n",
      "Epoch 614/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5895 - mean_squared_logarithmic_error: 6.8021e-04\n",
      "Epoch 615/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5830 - mean_squared_logarithmic_error: 5.4117e-04\n",
      "Epoch 616/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5852 - mean_squared_logarithmic_error: 5.9577e-04\n",
      "Epoch 617/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5848 - mean_squared_logarithmic_error: 5.5477e-04\n",
      "Epoch 618/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5910 - mean_squared_logarithmic_error: 6.6496e-04\n",
      "Epoch 619/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5943 - mean_squared_logarithmic_error: 7.6722e-04\n",
      "Epoch 620/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5895 - mean_squared_logarithmic_error: 6.3667e-04\n",
      "Epoch 621/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5897 - mean_squared_logarithmic_error: 6.7702e-04\n",
      "Epoch 622/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5866 - mean_squared_logarithmic_error: 7.3190e-04\n",
      "Epoch 623/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5877 - mean_squared_logarithmic_error: 6.1475e-04\n",
      "Epoch 624/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5840 - mean_squared_logarithmic_error: 5.8732e-04\n",
      "Epoch 625/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5828 - mean_squared_logarithmic_error: 5.9279e-04\n",
      "Epoch 626/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5884 - mean_squared_logarithmic_error: 6.2063e-04\n",
      "Epoch 627/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.5818 - mean_squared_logarithmic_error: 5.5265e-04\n",
      "Epoch 628/1000\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 520.5823 - mean_squared_logarithmic_error: 5.4744e-04\n",
      "Epoch 629/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5835 - mean_squared_logarithmic_error: 5.4185e-04\n",
      "Epoch 630/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5849 - mean_squared_logarithmic_error: 6.2367e-04\n",
      "Epoch 631/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5973 - mean_squared_logarithmic_error: 7.0165e-04\n",
      "Epoch 632/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 520.5855 - mean_squared_logarithmic_error: 5.8772e-04\n",
      "Epoch 633/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5837 - mean_squared_logarithmic_error: 5.6997e-04\n",
      "Epoch 634/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5844 - mean_squared_logarithmic_error: 5.8514e-04\n",
      "Epoch 635/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5828 - mean_squared_logarithmic_error: 5.2793e-04\n",
      "Epoch 636/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5817 - mean_squared_logarithmic_error: 5.3677e-04\n",
      "Epoch 637/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5913 - mean_squared_logarithmic_error: 6.2162e-04\n",
      "Epoch 638/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 520.5927 - mean_squared_logarithmic_error: 6.4449e-04\n",
      "Epoch 639/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5830 - mean_squared_logarithmic_error: 5.3012e-04\n",
      "Epoch 640/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5811 - mean_squared_logarithmic_error: 5.2688e-04\n",
      "Epoch 641/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5808 - mean_squared_logarithmic_error: 4.9896e-04\n",
      "Epoch 642/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5837 - mean_squared_logarithmic_error: 5.5287e-04\n",
      "Epoch 643/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5827 - mean_squared_logarithmic_error: 5.3038e-04\n",
      "Epoch 644/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5842 - mean_squared_logarithmic_error: 5.4730e-04\n",
      "Epoch 645/1000\n",
      "8000/8000 [==============================] - 1s 126us/sample - loss: 520.5800 - mean_squared_logarithmic_error: 4.9120e-04\n",
      "Epoch 646/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5826 - mean_squared_logarithmic_error: 5.6012e-04\n",
      "Epoch 647/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5813 - mean_squared_logarithmic_error: 5.0051e-04\n",
      "Epoch 648/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5802 - mean_squared_logarithmic_error: 5.1812e-04\n",
      "Epoch 649/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5854 - mean_squared_logarithmic_error: 5.4670e-04\n",
      "Epoch 650/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5891 - mean_squared_logarithmic_error: 5.9956e-04\n",
      "Epoch 651/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5827 - mean_squared_logarithmic_error: 5.4759e-04\n",
      "Epoch 652/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5861 - mean_squared_logarithmic_error: 5.6597e-04\n",
      "Epoch 653/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5857 - mean_squared_logarithmic_error: 5.3448e-04\n",
      "Epoch 654/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5806 - mean_squared_logarithmic_error: 5.0764e-04\n",
      "Epoch 655/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5927 - mean_squared_logarithmic_error: 6.1400e-04\n",
      "Epoch 656/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5862 - mean_squared_logarithmic_error: 6.1135e-04\n",
      "Epoch 657/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5972 - mean_squared_logarithmic_error: 7.2175e-04\n",
      "Epoch 658/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5857 - mean_squared_logarithmic_error: 5.8073e-04\n",
      "Epoch 659/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5796 - mean_squared_logarithmic_error: 4.5033e-04\n",
      "Epoch 660/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5800 - mean_squared_logarithmic_error: 4.9908e-04\n",
      "Epoch 661/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5852 - mean_squared_logarithmic_error: 5.4593e-04\n",
      "Epoch 662/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5828 - mean_squared_logarithmic_error: 5.1128e-04\n",
      "Epoch 663/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 520.5792 - mean_squared_logarithmic_error: 4.6157e-04\n",
      "Epoch 664/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5819 - mean_squared_logarithmic_error: 5.3172e-04\n",
      "Epoch 665/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5853 - mean_squared_logarithmic_error: 5.5592e-04\n",
      "Epoch 666/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.5855 - mean_squared_logarithmic_error: 5.1439e-04\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5824 - mean_squared_logarithmic_error: 4.9401e-04\n",
      "Epoch 668/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5798 - mean_squared_logarithmic_error: 4.9132e-04\n",
      "Epoch 669/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 520.5802 - mean_squared_logarithmic_error: 4.8457e-04\n",
      "Epoch 670/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5812 - mean_squared_logarithmic_error: 4.7611e-04\n",
      "Epoch 671/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.5834 - mean_squared_logarithmic_error: 4.9429e-04\n",
      "Epoch 672/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5795 - mean_squared_logarithmic_error: 4.6097e-04\n",
      "Epoch 673/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 520.5786 - mean_squared_logarithmic_error: 4.2985e-04\n",
      "Epoch 674/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5885 - mean_squared_logarithmic_error: 5.7862e-04\n",
      "Epoch 675/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5896 - mean_squared_logarithmic_error: 5.9166e-04\n",
      "Epoch 676/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5808 - mean_squared_logarithmic_error: 4.6495e-04\n",
      "Epoch 677/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5800 - mean_squared_logarithmic_error: 4.6146e-04\n",
      "Epoch 678/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5808 - mean_squared_logarithmic_error: 4.4415e-04\n",
      "Epoch 679/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5841 - mean_squared_logarithmic_error: 5.0679e-04\n",
      "Epoch 680/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5844 - mean_squared_logarithmic_error: 5.1731e-04\n",
      "Epoch 681/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5805 - mean_squared_logarithmic_error: 4.5155e-04\n",
      "Epoch 682/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 520.5850 - mean_squared_logarithmic_error: 5.4660e-04\n",
      "Epoch 683/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 520.5833 - mean_squared_logarithmic_error: 5.0294e-04\n",
      "Epoch 684/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5815 - mean_squared_logarithmic_error: 4.5480e-04\n",
      "Epoch 685/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5792 - mean_squared_logarithmic_error: 4.4862e-04\n",
      "Epoch 686/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5788 - mean_squared_logarithmic_error: 4.5700e-04\n",
      "Epoch 687/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5789 - mean_squared_logarithmic_error: 4.4101e-04\n",
      "Epoch 688/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5799 - mean_squared_logarithmic_error: 4.5971e-04\n",
      "Epoch 689/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5857 - mean_squared_logarithmic_error: 5.1742e-04\n",
      "Epoch 690/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5820 - mean_squared_logarithmic_error: 4.7017e-04\n",
      "Epoch 691/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5769 - mean_squared_logarithmic_error: 4.4032e-04\n",
      "Epoch 692/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5789 - mean_squared_logarithmic_error: 4.4416e-04\n",
      "Epoch 693/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5788 - mean_squared_logarithmic_error: 4.2484e-04\n",
      "Epoch 694/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.5808 - mean_squared_logarithmic_error: 4.5482e-04\n",
      "Epoch 695/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.5885 - mean_squared_logarithmic_error: 5.1432e-04\n",
      "Epoch 696/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5863 - mean_squared_logarithmic_error: 5.3409e-04\n",
      "Epoch 697/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5900 - mean_squared_logarithmic_error: 5.1615e-04\n",
      "Epoch 698/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5822 - mean_squared_logarithmic_error: 4.8617e-04\n",
      "Epoch 699/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5844 - mean_squared_logarithmic_error: 5.1659e-04\n",
      "Epoch 700/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5833 - mean_squared_logarithmic_error: 4.7789e-04\n",
      "Epoch 701/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5812 - mean_squared_logarithmic_error: 4.4541e-04\n",
      "Epoch 702/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5788 - mean_squared_logarithmic_error: 4.3939e-04\n",
      "Epoch 703/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5817 - mean_squared_logarithmic_error: 4.2344e-04\n",
      "Epoch 704/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.5895 - mean_squared_logarithmic_error: 5.5618e-04\n",
      "Epoch 705/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5796 - mean_squared_logarithmic_error: 4.3698e-04\n",
      "Epoch 706/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5835 - mean_squared_logarithmic_error: 4.2629e-04\n",
      "Epoch 707/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5756 - mean_squared_logarithmic_error: 3.8447e-04\n",
      "Epoch 708/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5765 - mean_squared_logarithmic_error: 3.8441e-04\n",
      "Epoch 709/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5795 - mean_squared_logarithmic_error: 4.2787e-04\n",
      "Epoch 710/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5783 - mean_squared_logarithmic_error: 4.1714e-04\n",
      "Epoch 711/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5886 - mean_squared_logarithmic_error: 5.3558e-04\n",
      "Epoch 712/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5852 - mean_squared_logarithmic_error: 5.0695e-04\n",
      "Epoch 713/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5781 - mean_squared_logarithmic_error: 4.1719e-04\n",
      "Epoch 714/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5756 - mean_squared_logarithmic_error: 3.8973e-04\n",
      "Epoch 715/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5814 - mean_squared_logarithmic_error: 4.4666e-04\n",
      "Epoch 716/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5816 - mean_squared_logarithmic_error: 4.5737e-04\n",
      "Epoch 717/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5806 - mean_squared_logarithmic_error: 4.3047e-04\n",
      "Epoch 718/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5813 - mean_squared_logarithmic_error: 4.4111e-04\n",
      "Epoch 719/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5774 - mean_squared_logarithmic_error: 3.8758e-04\n",
      "Epoch 720/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5783 - mean_squared_logarithmic_error: 4.3409e-04\n",
      "Epoch 721/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5846 - mean_squared_logarithmic_error: 4.5184e-04\n",
      "Epoch 722/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5793 - mean_squared_logarithmic_error: 3.8957e-04\n",
      "Epoch 723/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5818 - mean_squared_logarithmic_error: 4.8050e-04\n",
      "Epoch 724/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5792 - mean_squared_logarithmic_error: 4.1782e-04\n",
      "Epoch 725/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5812 - mean_squared_logarithmic_error: 4.5398e-04\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5801 - mean_squared_logarithmic_error: 4.1770e-04\n",
      "Epoch 727/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5801 - mean_squared_logarithmic_error: 3.8733e-04\n",
      "Epoch 728/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5795 - mean_squared_logarithmic_error: 4.2646e-04\n",
      "Epoch 729/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5814 - mean_squared_logarithmic_error: 4.2093e-04\n",
      "Epoch 730/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5791 - mean_squared_logarithmic_error: 4.1285e-04\n",
      "Epoch 731/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5782 - mean_squared_logarithmic_error: 3.7696e-04\n",
      "Epoch 732/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5846 - mean_squared_logarithmic_error: 4.6284e-04\n",
      "Epoch 733/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5781 - mean_squared_logarithmic_error: 4.1735e-04\n",
      "Epoch 734/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5807 - mean_squared_logarithmic_error: 4.6173e-04\n",
      "Epoch 735/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5819 - mean_squared_logarithmic_error: 4.1683e-04\n",
      "Epoch 736/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 520.5788 - mean_squared_logarithmic_error: 3.9204e-04\n",
      "Epoch 737/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5746 - mean_squared_logarithmic_error: 3.6891e-04\n",
      "Epoch 738/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5793 - mean_squared_logarithmic_error: 3.9265e-04\n",
      "Epoch 739/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5793 - mean_squared_logarithmic_error: 3.5699e-04\n",
      "Epoch 740/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5751 - mean_squared_logarithmic_error: 3.7413e-04\n",
      "Epoch 741/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5743 - mean_squared_logarithmic_error: 3.2268e-04\n",
      "Epoch 742/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5750 - mean_squared_logarithmic_error: 3.5814e-04\n",
      "Epoch 743/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5786 - mean_squared_logarithmic_error: 3.9649e-04\n",
      "Epoch 744/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5815 - mean_squared_logarithmic_error: 4.2126e-04\n",
      "Epoch 745/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5816 - mean_squared_logarithmic_error: 4.1069e-04\n",
      "Epoch 746/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5814 - mean_squared_logarithmic_error: 3.9136e-04\n",
      "Epoch 747/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5771 - mean_squared_logarithmic_error: 3.5908e-04\n",
      "Epoch 748/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5830 - mean_squared_logarithmic_error: 3.9564e-04\n",
      "Epoch 749/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5770 - mean_squared_logarithmic_error: 3.8192e-04\n",
      "Epoch 750/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5794 - mean_squared_logarithmic_error: 4.0089e-04\n",
      "Epoch 751/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5768 - mean_squared_logarithmic_error: 3.5947e-04\n",
      "Epoch 752/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5766 - mean_squared_logarithmic_error: 4.1078e-04\n",
      "Epoch 753/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5783 - mean_squared_logarithmic_error: 4.0124e-04\n",
      "Epoch 754/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5767 - mean_squared_logarithmic_error: 4.3307e-04\n",
      "Epoch 755/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5776 - mean_squared_logarithmic_error: 4.0604e-04\n",
      "Epoch 756/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5765 - mean_squared_logarithmic_error: 3.3615e-04\n",
      "Epoch 757/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5752 - mean_squared_logarithmic_error: 3.3178e-04\n",
      "Epoch 758/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5800 - mean_squared_logarithmic_error: 3.8922e-04\n",
      "Epoch 759/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5812 - mean_squared_logarithmic_error: 4.0865e-04\n",
      "Epoch 760/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5833 - mean_squared_logarithmic_error: 4.4318e-04\n",
      "Epoch 761/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5803 - mean_squared_logarithmic_error: 4.0492e-04\n",
      "Epoch 762/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5768 - mean_squared_logarithmic_error: 3.6190e-04\n",
      "Epoch 763/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 520.5754 - mean_squared_logarithmic_error: 3.3540e-04\n",
      "Epoch 764/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5777 - mean_squared_logarithmic_error: 3.7172e-04\n",
      "Epoch 765/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5801 - mean_squared_logarithmic_error: 3.9040e-04\n",
      "Epoch 766/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.5828 - mean_squared_logarithmic_error: 4.2993e-04\n",
      "Epoch 767/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 520.5778 - mean_squared_logarithmic_error: 3.7905e-04\n",
      "Epoch 768/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5858 - mean_squared_logarithmic_error: 4.7473e-04\n",
      "Epoch 769/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5772 - mean_squared_logarithmic_error: 3.5489e-04\n",
      "Epoch 770/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5800 - mean_squared_logarithmic_error: 3.8067e-04\n",
      "Epoch 771/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5739 - mean_squared_logarithmic_error: 3.2166e-04\n",
      "Epoch 772/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5786 - mean_squared_logarithmic_error: 4.0889e-04\n",
      "Epoch 773/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5753 - mean_squared_logarithmic_error: 3.2813e-04\n",
      "Epoch 774/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5731 - mean_squared_logarithmic_error: 2.9553e-04\n",
      "Epoch 775/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5748 - mean_squared_logarithmic_error: 3.1330e-04\n",
      "Epoch 776/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5765 - mean_squared_logarithmic_error: 3.5263e-04\n",
      "Epoch 777/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5744 - mean_squared_logarithmic_error: 3.1683e-04\n",
      "Epoch 778/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5739 - mean_squared_logarithmic_error: 3.2339e-04\n",
      "Epoch 779/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5753 - mean_squared_logarithmic_error: 3.1008e-04\n",
      "Epoch 780/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5771 - mean_squared_logarithmic_error: 3.3192e-04\n",
      "Epoch 781/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5752 - mean_squared_logarithmic_error: 3.4972e-04\n",
      "Epoch 782/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5741 - mean_squared_logarithmic_error: 2.9125e-04\n",
      "Epoch 783/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5733 - mean_squared_logarithmic_error: 3.1069e-04\n",
      "Epoch 784/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5745 - mean_squared_logarithmic_error: 3.3560e-04\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5767 - mean_squared_logarithmic_error: 3.3294e-04\n",
      "Epoch 786/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5762 - mean_squared_logarithmic_error: 3.4961e-04\n",
      "Epoch 787/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5731 - mean_squared_logarithmic_error: 3.0560e-04\n",
      "Epoch 788/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5734 - mean_squared_logarithmic_error: 3.2811e-04\n",
      "Epoch 789/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5726 - mean_squared_logarithmic_error: 2.8858e-04\n",
      "Epoch 790/1000\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 520.5768 - mean_squared_logarithmic_error: 3.4952e-04\n",
      "Epoch 791/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5778 - mean_squared_logarithmic_error: 3.2374e-04\n",
      "Epoch 792/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5738 - mean_squared_logarithmic_error: 3.1478e-04\n",
      "Epoch 793/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 520.5741 - mean_squared_logarithmic_error: 3.1794e-04\n",
      "Epoch 794/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5787 - mean_squared_logarithmic_error: 3.4232e-04\n",
      "Epoch 795/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5726 - mean_squared_logarithmic_error: 2.8627e-04\n",
      "Epoch 796/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5747 - mean_squared_logarithmic_error: 2.9923e-04\n",
      "Epoch 797/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5840 - mean_squared_logarithmic_error: 4.2575e-04\n",
      "Epoch 798/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5831 - mean_squared_logarithmic_error: 4.5715e-04\n",
      "Epoch 799/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5730 - mean_squared_logarithmic_error: 2.8883e-04\n",
      "Epoch 800/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5745 - mean_squared_logarithmic_error: 2.8912e-04\n",
      "Epoch 801/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5795 - mean_squared_logarithmic_error: 3.6307e-04\n",
      "Epoch 802/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5856 - mean_squared_logarithmic_error: 4.7923e-04\n",
      "Epoch 803/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5781 - mean_squared_logarithmic_error: 4.0766e-04\n",
      "Epoch 804/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5734 - mean_squared_logarithmic_error: 3.1443e-04\n",
      "Epoch 805/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5728 - mean_squared_logarithmic_error: 2.8597e-04\n",
      "Epoch 806/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5729 - mean_squared_logarithmic_error: 2.9004e-04\n",
      "Epoch 807/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.6826e-04\n",
      "Epoch 808/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5766 - mean_squared_logarithmic_error: 3.2798e-04\n",
      "Epoch 809/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5735 - mean_squared_logarithmic_error: 3.0210e-04\n",
      "Epoch 810/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5731 - mean_squared_logarithmic_error: 2.7651e-04\n",
      "Epoch 811/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5812 - mean_squared_logarithmic_error: 3.6917e-04\n",
      "Epoch 812/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5842 - mean_squared_logarithmic_error: 3.7719e-04\n",
      "Epoch 813/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5742 - mean_squared_logarithmic_error: 2.8589e-04\n",
      "Epoch 814/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5724 - mean_squared_logarithmic_error: 2.7775e-04\n",
      "Epoch 815/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5722 - mean_squared_logarithmic_error: 2.7059e-04\n",
      "Epoch 816/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.7141e-04\n",
      "Epoch 817/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5761 - mean_squared_logarithmic_error: 3.1023e-04\n",
      "Epoch 818/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5773 - mean_squared_logarithmic_error: 3.4566e-04\n",
      "Epoch 819/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5820 - mean_squared_logarithmic_error: 3.6893e-04\n",
      "Epoch 820/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5892 - mean_squared_logarithmic_error: 4.4014e-04\n",
      "Epoch 821/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5802 - mean_squared_logarithmic_error: 3.9803e-04\n",
      "Epoch 822/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5752 - mean_squared_logarithmic_error: 3.1515e-04\n",
      "Epoch 823/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5740 - mean_squared_logarithmic_error: 2.8990e-04\n",
      "Epoch 824/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5723 - mean_squared_logarithmic_error: 2.7740e-04\n",
      "Epoch 825/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5721 - mean_squared_logarithmic_error: 2.4830e-04\n",
      "Epoch 826/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5734 - mean_squared_logarithmic_error: 2.8800e-04\n",
      "Epoch 827/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5743 - mean_squared_logarithmic_error: 2.6560e-04\n",
      "Epoch 828/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5762 - mean_squared_logarithmic_error: 3.0961e-04\n",
      "Epoch 829/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5749 - mean_squared_logarithmic_error: 2.8692e-04\n",
      "Epoch 830/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5820 - mean_squared_logarithmic_error: 4.0346e-04\n",
      "Epoch 831/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5745 - mean_squared_logarithmic_error: 3.0411e-04\n",
      "Epoch 832/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5733 - mean_squared_logarithmic_error: 2.6301e-04\n",
      "Epoch 833/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.6057e-04\n",
      "Epoch 834/1000\n",
      "8000/8000 [==============================] - 1s 138us/sample - loss: 520.5771 - mean_squared_logarithmic_error: 3.2793e-04\n",
      "Epoch 835/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5744 - mean_squared_logarithmic_error: 3.0228e-04\n",
      "Epoch 836/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5718 - mean_squared_logarithmic_error: 2.4665e-04\n",
      "Epoch 837/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5714 - mean_squared_logarithmic_error: 2.5718e-04\n",
      "Epoch 838/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5738 - mean_squared_logarithmic_error: 2.7999e-04\n",
      "Epoch 839/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5972 - mean_squared_logarithmic_error: 5.4900e-04\n",
      "Epoch 840/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5921 - mean_squared_logarithmic_error: 4.8734e-04\n",
      "Epoch 841/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5733 - mean_squared_logarithmic_error: 2.5249e-04\n",
      "Epoch 842/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5727 - mean_squared_logarithmic_error: 2.6593e-04\n",
      "Epoch 843/1000\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 520.5740 - mean_squared_logarithmic_error: 2.7686e-04\n",
      "Epoch 844/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5717 - mean_squared_logarithmic_error: 2.4668e-04\n",
      "Epoch 845/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5722 - mean_squared_logarithmic_error: 2.5596e-04\n",
      "Epoch 846/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5718 - mean_squared_logarithmic_error: 2.5575e-04\n",
      "Epoch 847/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5738 - mean_squared_logarithmic_error: 2.7394e-04\n",
      "Epoch 848/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5817 - mean_squared_logarithmic_error: 3.2418e-04\n",
      "Epoch 849/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5787 - mean_squared_logarithmic_error: 2.9879e-04\n",
      "Epoch 850/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5714 - mean_squared_logarithmic_error: 2.5345e-04\n",
      "Epoch 851/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.4032e-04\n",
      "Epoch 852/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5712 - mean_squared_logarithmic_error: 2.5114e-04\n",
      "Epoch 853/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5716 - mean_squared_logarithmic_error: 2.5286e-04\n",
      "Epoch 854/1000\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 520.5726 - mean_squared_logarithmic_error: 2.7694e-04\n",
      "Epoch 855/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5710 - mean_squared_logarithmic_error: 2.2542e-04\n",
      "Epoch 856/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5704 - mean_squared_logarithmic_error: 2.1596e-04\n",
      "Epoch 857/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5730 - mean_squared_logarithmic_error: 2.4805e-04\n",
      "Epoch 858/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5747 - mean_squared_logarithmic_error: 2.7591e-04\n",
      "Epoch 859/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.7463e-04\n",
      "Epoch 860/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5745 - mean_squared_logarithmic_error: 2.6329e-04\n",
      "Epoch 861/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5716 - mean_squared_logarithmic_error: 2.4241e-04\n",
      "Epoch 862/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5810 - mean_squared_logarithmic_error: 3.4979e-04\n",
      "Epoch 863/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5732 - mean_squared_logarithmic_error: 2.5888e-04\n",
      "Epoch 864/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5728 - mean_squared_logarithmic_error: 2.7618e-04\n",
      "Epoch 865/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5723 - mean_squared_logarithmic_error: 2.3427e-04\n",
      "Epoch 866/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5723 - mean_squared_logarithmic_error: 2.4747e-04\n",
      "Epoch 867/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5735 - mean_squared_logarithmic_error: 2.7159e-04\n",
      "Epoch 868/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.7164e-04\n",
      "Epoch 869/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5750 - mean_squared_logarithmic_error: 2.7236e-04\n",
      "Epoch 870/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5781 - mean_squared_logarithmic_error: 2.9936e-04\n",
      "Epoch 871/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5734 - mean_squared_logarithmic_error: 2.7003e-04\n",
      "Epoch 872/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.4278e-04\n",
      "Epoch 873/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 2.3129e-04\n",
      "Epoch 874/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.4042e-04\n",
      "Epoch 875/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5744 - mean_squared_logarithmic_error: 2.5730e-04\n",
      "Epoch 876/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5735 - mean_squared_logarithmic_error: 2.6366e-04\n",
      "Epoch 877/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5739 - mean_squared_logarithmic_error: 2.6069e-04\n",
      "Epoch 878/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.3795e-04\n",
      "Epoch 879/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5712 - mean_squared_logarithmic_error: 2.2541e-04\n",
      "Epoch 880/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5720 - mean_squared_logarithmic_error: 2.3565e-04\n",
      "Epoch 881/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5745 - mean_squared_logarithmic_error: 2.4810e-04\n",
      "Epoch 882/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.6454e-04\n",
      "Epoch 883/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5742 - mean_squared_logarithmic_error: 2.7113e-04\n",
      "Epoch 884/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5824 - mean_squared_logarithmic_error: 3.3181e-04\n",
      "Epoch 885/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5815 - mean_squared_logarithmic_error: 3.2406e-04\n",
      "Epoch 886/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 520.5763 - mean_squared_logarithmic_error: 2.8231e-04\n",
      "Epoch 887/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5738 - mean_squared_logarithmic_error: 2.5147e-04\n",
      "Epoch 888/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5720 - mean_squared_logarithmic_error: 2.6254e-04\n",
      "Epoch 889/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5777 - mean_squared_logarithmic_error: 3.5084e-04\n",
      "Epoch 890/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5772 - mean_squared_logarithmic_error: 2.6927e-04\n",
      "Epoch 891/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 2.1368e-04\n",
      "Epoch 892/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5699 - mean_squared_logarithmic_error: 2.0041e-04\n",
      "Epoch 893/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.4248e-04\n",
      "Epoch 894/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5752 - mean_squared_logarithmic_error: 2.5317e-04\n",
      "Epoch 895/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5803 - mean_squared_logarithmic_error: 3.3181e-04\n",
      "Epoch 896/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5738 - mean_squared_logarithmic_error: 2.2868e-04\n",
      "Epoch 897/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5723 - mean_squared_logarithmic_error: 2.3487e-04\n",
      "Epoch 898/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5707 - mean_squared_logarithmic_error: 2.2614e-04\n",
      "Epoch 899/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5712 - mean_squared_logarithmic_error: 2.2475e-04\n",
      "Epoch 900/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5733 - mean_squared_logarithmic_error: 2.3156e-04\n",
      "Epoch 901/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5700 - mean_squared_logarithmic_error: 2.1036e-04\n",
      "Epoch 902/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 520.5709 - mean_squared_logarithmic_error: 2.0486e-04\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5708 - mean_squared_logarithmic_error: 2.1319e-04\n",
      "Epoch 904/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5701 - mean_squared_logarithmic_error: 2.1734e-04\n",
      "Epoch 905/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5702 - mean_squared_logarithmic_error: 2.0386e-04\n",
      "Epoch 906/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5737 - mean_squared_logarithmic_error: 2.3568e-04\n",
      "Epoch 907/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5753 - mean_squared_logarithmic_error: 2.6614e-04\n",
      "Epoch 908/1000\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 520.5763 - mean_squared_logarithmic_error: 2.8633e-04\n",
      "Epoch 909/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5772 - mean_squared_logarithmic_error: 3.0843e-04\n",
      "Epoch 910/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.2871e-04\n",
      "Epoch 911/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5757 - mean_squared_logarithmic_error: 3.0818e-04\n",
      "Epoch 912/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5732 - mean_squared_logarithmic_error: 2.4566e-04\n",
      "Epoch 913/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5716 - mean_squared_logarithmic_error: 2.5946e-04\n",
      "Epoch 914/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5717 - mean_squared_logarithmic_error: 2.1747e-04\n",
      "Epoch 915/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5712 - mean_squared_logarithmic_error: 2.1465e-04\n",
      "Epoch 916/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 520.5714 - mean_squared_logarithmic_error: 2.2500e-04\n",
      "Epoch 917/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5706 - mean_squared_logarithmic_error: 1.9345e-04\n",
      "Epoch 918/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5692 - mean_squared_logarithmic_error: 1.8905e-04\n",
      "Epoch 919/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5758 - mean_squared_logarithmic_error: 2.5114e-04\n",
      "Epoch 920/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5725 - mean_squared_logarithmic_error: 2.2344e-04\n",
      "Epoch 921/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5729 - mean_squared_logarithmic_error: 2.3993e-04\n",
      "Epoch 922/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5727 - mean_squared_logarithmic_error: 2.3916e-04\n",
      "Epoch 923/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5741 - mean_squared_logarithmic_error: 2.4453e-04\n",
      "Epoch 924/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5729 - mean_squared_logarithmic_error: 2.4070e-04\n",
      "Epoch 925/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5748 - mean_squared_logarithmic_error: 2.9669e-04\n",
      "Epoch 926/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5715 - mean_squared_logarithmic_error: 2.3608e-04\n",
      "Epoch 927/1000\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 520.5791 - mean_squared_logarithmic_error: 3.1271e-04\n",
      "Epoch 928/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5983 - mean_squared_logarithmic_error: 4.9310e-04\n",
      "Epoch 929/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5765 - mean_squared_logarithmic_error: 2.5426e-04\n",
      "Epoch 930/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5709 - mean_squared_logarithmic_error: 2.0313e-04\n",
      "Epoch 931/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5708 - mean_squared_logarithmic_error: 2.2096e-04\n",
      "Epoch 932/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5709 - mean_squared_logarithmic_error: 2.3462e-04\n",
      "Epoch 933/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5769 - mean_squared_logarithmic_error: 2.6036e-04\n",
      "Epoch 934/1000\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 520.5746 - mean_squared_logarithmic_error: 2.3342e-04\n",
      "Epoch 935/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 520.5706 - mean_squared_logarithmic_error: 2.0039e-04\n",
      "Epoch 936/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 520.5740 - mean_squared_logarithmic_error: 2.4534e-04\n",
      "Epoch 937/1000\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 520.5871 - mean_squared_logarithmic_error: 4.1975e-04\n",
      "Epoch 938/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5741 - mean_squared_logarithmic_error: 2.6724e-04\n",
      "Epoch 939/1000\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 520.5723 - mean_squared_logarithmic_error: 2.5410e-04\n",
      "Epoch 940/1000\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 520.5741 - mean_squared_logarithmic_error: 2.4449e-04\n",
      "Epoch 941/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5765 - mean_squared_logarithmic_error: 2.6042e-04\n",
      "Epoch 942/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.6051 - mean_squared_logarithmic_error: 5.5606e-04\n",
      "Epoch 943/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5927 - mean_squared_logarithmic_error: 4.2682e-04\n",
      "Epoch 944/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5743 - mean_squared_logarithmic_error: 2.5438e-04\n",
      "Epoch 945/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5694 - mean_squared_logarithmic_error: 1.9145e-04\n",
      "Epoch 946/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5695 - mean_squared_logarithmic_error: 1.9175e-04\n",
      "Epoch 947/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5694 - mean_squared_logarithmic_error: 1.9692e-04\n",
      "Epoch 948/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5698 - mean_squared_logarithmic_error: 2.0573e-04\n",
      "Epoch 949/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5711 - mean_squared_logarithmic_error: 2.2914e-04\n",
      "Epoch 950/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5712 - mean_squared_logarithmic_error: 2.1764e-04\n",
      "Epoch 951/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5721 - mean_squared_logarithmic_error: 2.1657e-04\n",
      "Epoch 952/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5727 - mean_squared_logarithmic_error: 2.4396e-04\n",
      "Epoch 953/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5717 - mean_squared_logarithmic_error: 2.1985e-04\n",
      "Epoch 954/1000\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 520.5686 - mean_squared_logarithmic_error: 1.7557e-04\n",
      "Epoch 955/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5687 - mean_squared_logarithmic_error: 1.7598e-04\n",
      "Epoch 956/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 520.5694 - mean_squared_logarithmic_error: 1.9122e-04\n",
      "Epoch 957/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5701 - mean_squared_logarithmic_error: 2.1390e-04\n",
      "Epoch 958/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5714 - mean_squared_logarithmic_error: 2.3325e-04\n",
      "Epoch 959/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 1.7548e-04\n",
      "Epoch 960/1000\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 520.5709 - mean_squared_logarithmic_error: 2.0471e-04\n",
      "Epoch 961/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 520.5688 - mean_squared_logarithmic_error: 1.7033e-04\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5710 - mean_squared_logarithmic_error: 2.0495e-04\n",
      "Epoch 963/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5708 - mean_squared_logarithmic_error: 2.2322e-04\n",
      "Epoch 964/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 520.5699 - mean_squared_logarithmic_error: 2.0002e-04\n",
      "Epoch 965/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5732 - mean_squared_logarithmic_error: 2.0965e-04\n",
      "Epoch 966/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5704 - mean_squared_logarithmic_error: 1.8853e-04\n",
      "Epoch 967/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5711 - mean_squared_logarithmic_error: 2.0573e-04\n",
      "Epoch 968/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5776 - mean_squared_logarithmic_error: 2.5039e-04\n",
      "Epoch 969/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5896 - mean_squared_logarithmic_error: 4.1536e-04\n",
      "Epoch 970/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5732 - mean_squared_logarithmic_error: 2.0298e-04\n",
      "Epoch 971/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5687 - mean_squared_logarithmic_error: 1.6758e-04\n",
      "Epoch 972/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5697 - mean_squared_logarithmic_error: 1.7333e-04\n",
      "Epoch 973/1000\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 520.5724 - mean_squared_logarithmic_error: 2.2570e-04\n",
      "Epoch 974/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 520.5727 - mean_squared_logarithmic_error: 2.1267e-04\n",
      "Epoch 975/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5743 - mean_squared_logarithmic_error: 2.4581e-04\n",
      "Epoch 976/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5698 - mean_squared_logarithmic_error: 1.9093e-04\n",
      "Epoch 977/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5689 - mean_squared_logarithmic_error: 1.7134e-04\n",
      "Epoch 978/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5713 - mean_squared_logarithmic_error: 1.8880e-04\n",
      "Epoch 979/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 2.0590e-04\n",
      "Epoch 980/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5708 - mean_squared_logarithmic_error: 1.9216e-04\n",
      "Epoch 981/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 520.5696 - mean_squared_logarithmic_error: 1.7630e-04\n",
      "Epoch 982/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5691 - mean_squared_logarithmic_error: 1.7311e-04\n",
      "Epoch 983/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 1.8942e-04\n",
      "Epoch 984/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 520.5790 - mean_squared_logarithmic_error: 2.8199e-04\n",
      "Epoch 985/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5731 - mean_squared_logarithmic_error: 2.3972e-04\n",
      "Epoch 986/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 1.9797e-04\n",
      "Epoch 987/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5730 - mean_squared_logarithmic_error: 2.1913e-04\n",
      "Epoch 988/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 2.1940e-04\n",
      "Epoch 989/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5696 - mean_squared_logarithmic_error: 1.9951e-04\n",
      "Epoch 990/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 520.5703 - mean_squared_logarithmic_error: 1.8144e-04\n",
      "Epoch 991/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5694 - mean_squared_logarithmic_error: 1.7103e-04\n",
      "Epoch 992/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 520.5705 - mean_squared_logarithmic_error: 1.7974e-04\n",
      "Epoch 993/1000\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 520.5693 - mean_squared_logarithmic_error: 1.8846e-04\n",
      "Epoch 994/1000\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 520.5711 - mean_squared_logarithmic_error: 1.8988e-04\n",
      "Epoch 995/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 520.5689 - mean_squared_logarithmic_error: 1.6908e-04\n",
      "Epoch 996/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 520.5689 - mean_squared_logarithmic_error: 1.6607e-04\n",
      "Epoch 997/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 520.5698 - mean_squared_logarithmic_error: 1.8569e-04\n",
      "Epoch 998/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 520.5699 - mean_squared_logarithmic_error: 1.8627e-04\n",
      "Epoch 999/1000\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 520.5690 - mean_squared_logarithmic_error: 1.7178e-04\n",
      "Epoch 1000/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 520.5694 - mean_squared_logarithmic_error: 1.5988e-04\n"
     ]
    }
   ],
   "source": [
    "MultiplicationTraining = Training_Tensorflow(OutputVector='Multiplication')\n",
    "MultiplicationTraining.TrainTheModel(optimizer='adam',activation='selu',epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.77"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiplicationTraining.PredictOneVal(A=11,B=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see it is relatively difficult. Why don't you play with it and find out a good solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us move to Sin and Cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.6173 - mean_squared_logarithmic_error: 0.1179\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.6075 - mean_squared_logarithmic_error: 0.1172\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5987 - mean_squared_logarithmic_error: 0.1166\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5907 - mean_squared_logarithmic_error: 0.1161\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5836 - mean_squared_logarithmic_error: 0.1157\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5771 - mean_squared_logarithmic_error: 0.1154\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5712 - mean_squared_logarithmic_error: 0.1151\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5658 - mean_squared_logarithmic_error: 0.1149\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5609 - mean_squared_logarithmic_error: 0.1147\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5564 - mean_squared_logarithmic_error: 0.1146\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5523 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5485 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5451 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5419 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5390 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5363 - mean_squared_logarithmic_error: 0.1145\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5338 - mean_squared_logarithmic_error: 0.1146\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5314 - mean_squared_logarithmic_error: 0.1147\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5293 - mean_squared_logarithmic_error: 0.1148\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5273 - mean_squared_logarithmic_error: 0.1149\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.5254 - mean_squared_logarithmic_error: 0.1150\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5237 - mean_squared_logarithmic_error: 0.1152\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5221 - mean_squared_logarithmic_error: 0.1153\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.5206 - mean_squared_logarithmic_error: 0.1155\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5192 - mean_squared_logarithmic_error: 0.1156\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5179 - mean_squared_logarithmic_error: 0.1158\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5166 - mean_squared_logarithmic_error: 0.1159\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5155 - mean_squared_logarithmic_error: 0.1161\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5144 - mean_squared_logarithmic_error: 0.1163\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.5134 - mean_squared_logarithmic_error: 0.1164\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5125 - mean_squared_logarithmic_error: 0.1166\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.5116 - mean_squared_logarithmic_error: 0.1168\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5107 - mean_squared_logarithmic_error: 0.1170\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5099 - mean_squared_logarithmic_error: 0.1171\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5092 - mean_squared_logarithmic_error: 0.1173\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5085 - mean_squared_logarithmic_error: 0.1175\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5078 - mean_squared_logarithmic_error: 0.1177\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.5072 - mean_squared_logarithmic_error: 0.1178\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.5066 - mean_squared_logarithmic_error: 0.1180\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.5061 - mean_squared_logarithmic_error: 0.1182\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.5055 - mean_squared_logarithmic_error: 0.1183\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5050 - mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5046 - mean_squared_logarithmic_error: 0.1187\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 0.5041 - mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5037 - mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5033 - mean_squared_logarithmic_error: 0.1192\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.5029 - mean_squared_logarithmic_error: 0.1193\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5026 - mean_squared_logarithmic_error: 0.1195\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5022 - mean_squared_logarithmic_error: 0.1197\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5019 - mean_squared_logarithmic_error: 0.1198\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5016 - mean_squared_logarithmic_error: 0.1200\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5013 - mean_squared_logarithmic_error: 0.1201\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.5010 - mean_squared_logarithmic_error: 0.1203\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.5007 - mean_squared_logarithmic_error: 0.1204\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.5005 - mean_squared_logarithmic_error: 0.1206\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.5002 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5000 - mean_squared_logarithmic_error: 0.1209\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4998 - mean_squared_logarithmic_error: 0.1210\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.4996 - mean_squared_logarithmic_error: 0.1211\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4994 - mean_squared_logarithmic_error: 0.1213\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4992 - mean_squared_logarithmic_error: 0.1214\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4990 - mean_squared_logarithmic_error: 0.1215\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4988 - mean_squared_logarithmic_error: 0.1217\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4986 - mean_squared_logarithmic_error: 0.1218\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4985 - mean_squared_logarithmic_error: 0.1219\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4983 - mean_squared_logarithmic_error: 0.1220\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4982 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4980 - mean_squared_logarithmic_error: 0.1223\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.4979 - mean_squared_logarithmic_error: 0.1224\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4978 - mean_squared_logarithmic_error: 0.1225\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.4977 - mean_squared_logarithmic_error: 0.1226\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.4975 - mean_squared_logarithmic_error: 0.1227\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4974 - mean_squared_logarithmic_error: 0.1228\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4973 - mean_squared_logarithmic_error: 0.1230\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.4972 - mean_squared_logarithmic_error: 0.1231\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.4971 - mean_squared_logarithmic_error: 0.1232\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4970 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.4969 - mean_squared_logarithmic_error: 0.1234\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 0.4968 - mean_squared_logarithmic_error: 0.1235\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4968 - mean_squared_logarithmic_error: 0.1236\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4967 - mean_squared_logarithmic_error: 0.1237\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.4966 - mean_squared_logarithmic_error: 0.1237\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4965 - mean_squared_logarithmic_error: 0.1238\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4965 - mean_squared_logarithmic_error: 0.1239\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.4964 - mean_squared_logarithmic_error: 0.1240\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4963 - mean_squared_logarithmic_error: 0.1241\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4963 - mean_squared_logarithmic_error: 0.1242\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4962 - mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4961 - mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4961 - mean_squared_logarithmic_error: 0.1244\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4960 - mean_squared_logarithmic_error: 0.1245\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4960 - mean_squared_logarithmic_error: 0.1246\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4959 - mean_squared_logarithmic_error: 0.1246\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4959 - mean_squared_logarithmic_error: 0.1247\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4958 - mean_squared_logarithmic_error: 0.1248\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.4958 - mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.4957 - mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4957 - mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.4957 - mean_squared_logarithmic_error: 0.1251\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.4956 - mean_squared_logarithmic_error: 0.1251\n"
     ]
    }
   ],
   "source": [
    "SinTraining = Training_Tensorflow(OutputVector='Sin(Addition)')\n",
    "SinTraining.TrainTheModel(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.6360 - mean_squared_logarithmic_error: 0.1208\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.6255 - mean_squared_logarithmic_error: 0.1201\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.6160 - mean_squared_logarithmic_error: 0.1194\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.6075 - mean_squared_logarithmic_error: 0.1189\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5998 - mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5928 - mean_squared_logarithmic_error: 0.1181\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5865 - mean_squared_logarithmic_error: 0.1178\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5808 - mean_squared_logarithmic_error: 0.1175\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5756 - mean_squared_logarithmic_error: 0.1173\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5708 - mean_squared_logarithmic_error: 0.1172\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5665 - mean_squared_logarithmic_error: 0.1171\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5625 - mean_squared_logarithmic_error: 0.1171\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5588 - mean_squared_logarithmic_error: 0.1170\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5554 - mean_squared_logarithmic_error: 0.1170\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5523 - mean_squared_logarithmic_error: 0.1171\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5495 - mean_squared_logarithmic_error: 0.1171\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5468 - mean_squared_logarithmic_error: 0.1172\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5444 - mean_squared_logarithmic_error: 0.1173\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5421 - mean_squared_logarithmic_error: 0.1174\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5400 - mean_squared_logarithmic_error: 0.1175\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5381 - mean_squared_logarithmic_error: 0.1177\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5363 - mean_squared_logarithmic_error: 0.1178\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5346 - mean_squared_logarithmic_error: 0.1180\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5330 - mean_squared_logarithmic_error: 0.1181\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5315 - mean_squared_logarithmic_error: 0.1183\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5301 - mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5289 - mean_squared_logarithmic_error: 0.1186\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5277 - mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5265 - mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5255 - mean_squared_logarithmic_error: 0.1192\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5245 - mean_squared_logarithmic_error: 0.1194\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5236 - mean_squared_logarithmic_error: 0.1195\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5227 - mean_squared_logarithmic_error: 0.1197\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5219 - mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5211 - mean_squared_logarithmic_error: 0.1201\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5203 - mean_squared_logarithmic_error: 0.1203\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5197 - mean_squared_logarithmic_error: 0.1205\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5190 - mean_squared_logarithmic_error: 0.1207\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5184 - mean_squared_logarithmic_error: 0.1209\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.5178 - mean_squared_logarithmic_error: 0.1211\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5173 - mean_squared_logarithmic_error: 0.1212\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5168 - mean_squared_logarithmic_error: 0.1214\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5163 - mean_squared_logarithmic_error: 0.1216\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5158 - mean_squared_logarithmic_error: 0.1218\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5154 - mean_squared_logarithmic_error: 0.1220\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.5149 - mean_squared_logarithmic_error: 0.1222\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5145 - mean_squared_logarithmic_error: 0.1223\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5142 - mean_squared_logarithmic_error: 0.1225\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5138 - mean_squared_logarithmic_error: 0.1227\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5135 - mean_squared_logarithmic_error: 0.1228\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5131 - mean_squared_logarithmic_error: 0.1230\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.5128 - mean_squared_logarithmic_error: 0.1232\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5125 - mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5123 - mean_squared_logarithmic_error: 0.1235\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5120 - mean_squared_logarithmic_error: 0.1237\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5117 - mean_squared_logarithmic_error: 0.1238\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5115 - mean_squared_logarithmic_error: 0.1240\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.5113 - mean_squared_logarithmic_error: 0.1241\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5111 - mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.5109 - mean_squared_logarithmic_error: 0.1244\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.5107 - mean_squared_logarithmic_error: 0.1246\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.5105 - mean_squared_logarithmic_error: 0.1247\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5103 - mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.5101 - mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5099 - mean_squared_logarithmic_error: 0.1252\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5098 - mean_squared_logarithmic_error: 0.1253\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5096 - mean_squared_logarithmic_error: 0.1254\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5095 - mean_squared_logarithmic_error: 0.1256\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5093 - mean_squared_logarithmic_error: 0.1257\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5092 - mean_squared_logarithmic_error: 0.1258\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5091 - mean_squared_logarithmic_error: 0.1260\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5090 - mean_squared_logarithmic_error: 0.1261\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5088 - mean_squared_logarithmic_error: 0.1262\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5087 - mean_squared_logarithmic_error: 0.1263\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5086 - mean_squared_logarithmic_error: 0.1264\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5085 - mean_squared_logarithmic_error: 0.1266\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5084 - mean_squared_logarithmic_error: 0.1267\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5083 - mean_squared_logarithmic_error: 0.1268\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5082 - mean_squared_logarithmic_error: 0.1269\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5081 - mean_squared_logarithmic_error: 0.1270\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5081 - mean_squared_logarithmic_error: 0.1271\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5080 - mean_squared_logarithmic_error: 0.1272\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5079 - mean_squared_logarithmic_error: 0.1273\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5078 - mean_squared_logarithmic_error: 0.1274\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5078 - mean_squared_logarithmic_error: 0.1275\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5077 - mean_squared_logarithmic_error: 0.1276\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5076 - mean_squared_logarithmic_error: 0.1277\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5076 - mean_squared_logarithmic_error: 0.1278\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5075 - mean_squared_logarithmic_error: 0.1279\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5074 - mean_squared_logarithmic_error: 0.1280\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5074 - mean_squared_logarithmic_error: 0.1281\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.5073 - mean_squared_logarithmic_error: 0.1282\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5073 - mean_squared_logarithmic_error: 0.1283\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5072 - mean_squared_logarithmic_error: 0.1284\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5072 - mean_squared_logarithmic_error: 0.1285\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.5071 - mean_squared_logarithmic_error: 0.1285\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5071 - mean_squared_logarithmic_error: 0.1286\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.5070 - mean_squared_logarithmic_error: 0.1287\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.5070 - mean_squared_logarithmic_error: 0.1288\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.5070 - mean_squared_logarithmic_error: 0.1289\n"
     ]
    }
   ],
   "source": [
    "CosTraining = Training_Tensorflow(OutputVector='Cos(Addition)')\n",
    "CosTraining.TrainTheModel(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SinTraining.PredictOneVal(A=0.5,B=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CosTraining.PredictOneVal(A=0.0,B=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like it is not working for Sin and Cos well either. Now we will see 2^Addition and log(Addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/250\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 1383854080.0000 - mean_squared_logarithmic_error: 11.2606\n",
      "Epoch 2/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1383667156.0000 - mean_squared_logarithmic_error: 6.6814\n",
      "Epoch 3/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1383343174.0000 - mean_squared_logarithmic_error: 4.8074\n",
      "Epoch 4/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1382873464.0000 - mean_squared_logarithmic_error: 3.9258\n",
      "Epoch 5/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1382282115.0000 - mean_squared_logarithmic_error: 3.5458\n",
      "Epoch 6/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1381541672.0000 - mean_squared_logarithmic_error: 3.4339\n",
      "Epoch 7/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1380729412.0000 - mean_squared_logarithmic_error: 3.4614\n",
      "Epoch 8/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1379724000.0000 - mean_squared_logarithmic_error: 3.5640\n",
      "Epoch 9/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1378644344.0000 - mean_squared_logarithmic_error: 3.7125\n",
      "Epoch 10/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1377410332.0000 - mean_squared_logarithmic_error: 3.8968\n",
      "Epoch 11/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1376093364.0000 - mean_squared_logarithmic_error: 4.1037\n",
      "Epoch 12/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1374577700.0000 - mean_squared_logarithmic_error: 4.3199\n",
      "Epoch 13/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1373017706.0000 - mean_squared_logarithmic_error: 4.5485\n",
      "Epoch 14/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1371250108.0000 - mean_squared_logarithmic_error: 4.7742\n",
      "Epoch 15/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1369461985.0000 - mean_squared_logarithmic_error: 5.0033\n",
      "Epoch 16/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1367501340.0000 - mean_squared_logarithmic_error: 5.2390\n",
      "Epoch 17/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1365476508.0000 - mean_squared_logarithmic_error: 5.4662\n",
      "Epoch 18/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1363284850.0000 - mean_squared_logarithmic_error: 5.6852\n",
      "Epoch 19/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1361082604.0000 - mean_squared_logarithmic_error: 5.9098\n",
      "Epoch 20/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1358706060.0000 - mean_squared_logarithmic_error: 6.1237\n",
      "Epoch 21/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1356248272.0000 - mean_squared_logarithmic_error: 6.3331\n",
      "Epoch 22/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1353637730.0000 - mean_squared_logarithmic_error: 6.5294\n",
      "Epoch 23/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1351159542.0000 - mean_squared_logarithmic_error: 6.7316\n",
      "Epoch 24/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1348409241.0000 - mean_squared_logarithmic_error: 6.9234\n",
      "Epoch 25/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1345603602.0000 - mean_squared_logarithmic_error: 7.1097\n",
      "Epoch 26/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1342773040.0000 - mean_squared_logarithmic_error: 7.2838\n",
      "Epoch 27/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1339796397.0000 - mean_squared_logarithmic_error: 7.4505\n",
      "Epoch 28/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1336855148.0000 - mean_squared_logarithmic_error: 7.6108\n",
      "Epoch 29/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1333955410.5000 - mean_squared_logarithmic_error: 7.7712\n",
      "Epoch 30/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1330598133.0000 - mean_squared_logarithmic_error: 7.9015\n",
      "Epoch 31/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1327587326.0000 - mean_squared_logarithmic_error: 8.0267\n",
      "Epoch 32/250\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 1324406954.0000 - mean_squared_logarithmic_error: 8.1457\n",
      "Epoch 33/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1321250757.0000 - mean_squared_logarithmic_error: 8.2524\n",
      "Epoch 34/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1317911706.0000 - mean_squared_logarithmic_error: 8.3391\n",
      "Epoch 35/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1314457704.0000 - mean_squared_logarithmic_error: 8.3980\n",
      "Epoch 36/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1311238708.0000 - mean_squared_logarithmic_error: 8.4453\n",
      "Epoch 37/250\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 1307775254.0000 - mean_squared_logarithmic_error: 8.4769\n",
      "Epoch 38/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1304451711.0000 - mean_squared_logarithmic_error: 8.5006\n",
      "Epoch 39/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1300851065.0000 - mean_squared_logarithmic_error: 8.5061\n",
      "Epoch 40/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1297308493.0000 - mean_squared_logarithmic_error: 8.4834\n",
      "Epoch 41/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1293760650.0000 - mean_squared_logarithmic_error: 8.4518\n",
      "Epoch 42/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 1290330844.0000 - mean_squared_logarithmic_error: 8.4275\n",
      "Epoch 43/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1286721602.0000 - mean_squared_logarithmic_error: 8.3971\n",
      "Epoch 44/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1283081178.0000 - mean_squared_logarithmic_error: 8.3672\n",
      "Epoch 45/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1279323066.0000 - mean_squared_logarithmic_error: 8.3089\n",
      "Epoch 46/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1275856208.0000 - mean_squared_logarithmic_error: 8.2696\n",
      "Epoch 47/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1272170532.0000 - mean_squared_logarithmic_error: 8.2111\n",
      "Epoch 48/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1268464220.0000 - mean_squared_logarithmic_error: 8.1466\n",
      "Epoch 49/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1264850236.0000 - mean_squared_logarithmic_error: 8.0977\n",
      "Epoch 50/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1261205196.0000 - mean_squared_logarithmic_error: 8.0591\n",
      "Epoch 51/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1257456983.0000 - mean_squared_logarithmic_error: 8.0201\n",
      "Epoch 52/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 1253876356.0000 - mean_squared_logarithmic_error: 7.9957\n",
      "Epoch 53/250\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 1250154904.0000 - mean_squared_logarithmic_error: 7.9713\n",
      "Epoch 54/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 1246669244.0000 - mean_squared_logarithmic_error: 7.9532\n",
      "Epoch 55/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 1242861414.0000 - mean_squared_logarithmic_error: 7.9265\n",
      "Epoch 56/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1239337451.0000 - mean_squared_logarithmic_error: 7.9056\n",
      "Epoch 57/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1235741654.0000 - mean_squared_logarithmic_error: 7.8848\n",
      "Epoch 58/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1232200648.0000 - mean_squared_logarithmic_error: 7.8638\n",
      "Epoch 59/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1228468763.0000 - mean_squared_logarithmic_error: 7.8399\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1225127406.0000 - mean_squared_logarithmic_error: 7.8259\n",
      "Epoch 61/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1221557048.0000 - mean_squared_logarithmic_error: 7.8115\n",
      "Epoch 62/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1217998138.0000 - mean_squared_logarithmic_error: 7.7881\n",
      "Epoch 63/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1214556209.0000 - mean_squared_logarithmic_error: 7.7647\n",
      "Epoch 64/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1211273072.0000 - mean_squared_logarithmic_error: 7.7510\n",
      "Epoch 65/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 1207681530.0000 - mean_squared_logarithmic_error: 7.7230\n",
      "Epoch 66/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1204256208.0000 - mean_squared_logarithmic_error: 7.6929\n",
      "Epoch 67/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 1201180394.0000 - mean_squared_logarithmic_error: 7.6799\n",
      "Epoch 68/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1197699846.0000 - mean_squared_logarithmic_error: 7.6614\n",
      "Epoch 69/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1194453884.0000 - mean_squared_logarithmic_error: 7.6428\n",
      "Epoch 70/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1191194884.0000 - mean_squared_logarithmic_error: 7.6161\n",
      "Epoch 71/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1188102790.0000 - mean_squared_logarithmic_error: 7.6017\n",
      "Epoch 72/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1184887264.0000 - mean_squared_logarithmic_error: 7.5888\n",
      "Epoch 73/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1181711119.0000 - mean_squared_logarithmic_error: 7.5681\n",
      "Epoch 74/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1178576740.0000 - mean_squared_logarithmic_error: 7.5370\n",
      "Epoch 75/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1175632037.5000 - mean_squared_logarithmic_error: 7.5196\n",
      "Epoch 76/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1172475183.0000 - mean_squared_logarithmic_error: 7.4926\n",
      "Epoch 77/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1169545542.0000 - mean_squared_logarithmic_error: 7.4656\n",
      "Epoch 78/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1166701192.0000 - mean_squared_logarithmic_error: 7.4490\n",
      "Epoch 79/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1163721862.0000 - mean_squared_logarithmic_error: 7.4268\n",
      "Epoch 80/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1160851106.0000 - mean_squared_logarithmic_error: 7.3971\n",
      "Epoch 81/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1157982277.0000 - mean_squared_logarithmic_error: 7.3716\n",
      "Epoch 82/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1155225906.0000 - mean_squared_logarithmic_error: 7.3521\n",
      "Epoch 83/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 1152452898.0000 - mean_squared_logarithmic_error: 7.3268\n",
      "Epoch 84/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1149804408.0000 - mean_squared_logarithmic_error: 7.3047\n",
      "Epoch 85/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1147176141.0000 - mean_squared_logarithmic_error: 7.2757\n",
      "Epoch 86/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1144383226.5000 - mean_squared_logarithmic_error: 7.2408\n",
      "Epoch 87/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 1141864556.0000 - mean_squared_logarithmic_error: 7.2089\n",
      "Epoch 88/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1139315372.0000 - mean_squared_logarithmic_error: 7.1820\n",
      "Epoch 89/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1136706780.0000 - mean_squared_logarithmic_error: 7.1456\n",
      "Epoch 90/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1134359940.0000 - mean_squared_logarithmic_error: 7.1168\n",
      "Epoch 91/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1131999033.0000 - mean_squared_logarithmic_error: 7.0928\n",
      "Epoch 92/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1129389981.0000 - mean_squared_logarithmic_error: 7.0544\n",
      "Epoch 93/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1127126106.0000 - mean_squared_logarithmic_error: 7.0224\n",
      "Epoch 94/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1124720283.0000 - mean_squared_logarithmic_error: 6.9858\n",
      "Epoch 95/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1122563952.0000 - mean_squared_logarithmic_error: 6.9654\n",
      "Epoch 96/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1120363824.0000 - mean_squared_logarithmic_error: 6.9457\n",
      "Epoch 97/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1118102423.0000 - mean_squared_logarithmic_error: 6.9230\n",
      "Epoch 98/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1115807632.0000 - mean_squared_logarithmic_error: 6.8804\n",
      "Epoch 99/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1113717132.0000 - mean_squared_logarithmic_error: 6.8457\n",
      "Epoch 100/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1111485258.0000 - mean_squared_logarithmic_error: 6.7994\n",
      "Epoch 101/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1109594971.0000 - mean_squared_logarithmic_error: 6.7560\n",
      "Epoch 102/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1107559096.0000 - mean_squared_logarithmic_error: 6.7420\n",
      "Epoch 103/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1105382246.0000 - mean_squared_logarithmic_error: 6.7147\n",
      "Epoch 104/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 1103454248.0000 - mean_squared_logarithmic_error: 6.6775\n",
      "Epoch 105/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1101451201.0000 - mean_squared_logarithmic_error: 6.6354\n",
      "Epoch 106/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1099602680.0000 - mean_squared_logarithmic_error: 6.6115\n",
      "Epoch 107/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1097661006.0000 - mean_squared_logarithmic_error: 6.5800\n",
      "Epoch 108/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1095692006.5000 - mean_squared_logarithmic_error: 6.5411\n",
      "Epoch 109/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1093938484.0000 - mean_squared_logarithmic_error: 6.5070\n",
      "Epoch 110/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1092065569.0000 - mean_squared_logarithmic_error: 6.4699\n",
      "Epoch 111/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1090394496.0000 - mean_squared_logarithmic_error: 6.4399\n",
      "Epoch 112/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1088470904.0000 - mean_squared_logarithmic_error: 6.4096\n",
      "Epoch 113/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1086716890.0000 - mean_squared_logarithmic_error: 6.3686\n",
      "Epoch 114/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1084978552.0000 - mean_squared_logarithmic_error: 6.3240\n",
      "Epoch 115/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1083266124.0000 - mean_squared_logarithmic_error: 6.2790\n",
      "Epoch 116/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1081645704.0000 - mean_squared_logarithmic_error: 6.2490\n",
      "Epoch 117/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1079928259.0000 - mean_squared_logarithmic_error: 6.2055\n",
      "Epoch 118/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1078287940.0000 - mean_squared_logarithmic_error: 6.1659\n",
      "Epoch 119/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1076760098.0000 - mean_squared_logarithmic_error: 6.1353\n",
      "Epoch 120/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1075110709.0000 - mean_squared_logarithmic_error: 6.1027\n",
      "Epoch 121/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 1073483807.0000 - mean_squared_logarithmic_error: 6.0769\n",
      "Epoch 122/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1071973086.0000 - mean_squared_logarithmic_error: 6.0475\n",
      "Epoch 123/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1070416367.0000 - mean_squared_logarithmic_error: 6.0241\n",
      "Epoch 124/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1068894021.0000 - mean_squared_logarithmic_error: 5.9881\n",
      "Epoch 125/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1067435744.0000 - mean_squared_logarithmic_error: 5.9541\n",
      "Epoch 126/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1066006870.0000 - mean_squared_logarithmic_error: 5.9351\n",
      "Epoch 127/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1064415538.0000 - mean_squared_logarithmic_error: 5.9057\n",
      "Epoch 128/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1063064668.0000 - mean_squared_logarithmic_error: 5.8791\n",
      "Epoch 129/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1061632687.0000 - mean_squared_logarithmic_error: 5.8578\n",
      "Epoch 130/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1060191822.5000 - mean_squared_logarithmic_error: 5.8275\n",
      "Epoch 131/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1058733026.0000 - mean_squared_logarithmic_error: 5.7930\n",
      "Epoch 132/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1057411156.0000 - mean_squared_logarithmic_error: 5.7633\n",
      "Epoch 133/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1055996552.0000 - mean_squared_logarithmic_error: 5.7471\n",
      "Epoch 134/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1054657404.0000 - mean_squared_logarithmic_error: 5.7168\n",
      "Epoch 135/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1053396339.0000 - mean_squared_logarithmic_error: 5.6901\n",
      "Epoch 136/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 1051983194.0000 - mean_squared_logarithmic_error: 5.6641\n",
      "Epoch 137/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 1050749789.0000 - mean_squared_logarithmic_error: 5.6350\n",
      "Epoch 138/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1049356110.0000 - mean_squared_logarithmic_error: 5.6028\n",
      "Epoch 139/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1048148942.0000 - mean_squared_logarithmic_error: 5.5842\n",
      "Epoch 140/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 1046810092.0000 - mean_squared_logarithmic_error: 5.5567\n",
      "Epoch 141/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 1045577578.0000 - mean_squared_logarithmic_error: 5.5317\n",
      "Epoch 142/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1044364078.0000 - mean_squared_logarithmic_error: 5.5093\n",
      "Epoch 143/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1043130966.0000 - mean_squared_logarithmic_error: 5.4850\n",
      "Epoch 144/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1041908214.0000 - mean_squared_logarithmic_error: 5.4616\n",
      "Epoch 145/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1040643202.0000 - mean_squared_logarithmic_error: 5.4496\n",
      "Epoch 146/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1039536557.5000 - mean_squared_logarithmic_error: 5.4398\n",
      "Epoch 147/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 1038320483.5000 - mean_squared_logarithmic_error: 5.4109\n",
      "Epoch 148/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1037084410.0000 - mean_squared_logarithmic_error: 5.3842\n",
      "Epoch 149/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1035979845.0000 - mean_squared_logarithmic_error: 5.3631\n",
      "Epoch 150/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1034808872.0000 - mean_squared_logarithmic_error: 5.3443\n",
      "Epoch 151/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1033621364.0000 - mean_squared_logarithmic_error: 5.3256\n",
      "Epoch 152/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1032520087.0000 - mean_squared_logarithmic_error: 5.3063\n",
      "Epoch 153/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1031400487.0000 - mean_squared_logarithmic_error: 5.2743\n",
      "Epoch 154/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1030286542.0000 - mean_squared_logarithmic_error: 5.2522\n",
      "Epoch 155/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1029122992.0000 - mean_squared_logarithmic_error: 5.2416\n",
      "Epoch 156/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1028072618.0000 - mean_squared_logarithmic_error: 5.2329\n",
      "Epoch 157/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1026922672.0000 - mean_squared_logarithmic_error: 5.2234\n",
      "Epoch 158/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1025809556.0000 - mean_squared_logarithmic_error: 5.2134\n",
      "Epoch 159/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1024771759.0000 - mean_squared_logarithmic_error: 5.1994\n",
      "Epoch 160/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1023857246.0000 - mean_squared_logarithmic_error: 5.1808\n",
      "Epoch 161/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1022642575.0000 - mean_squared_logarithmic_error: 5.1610\n",
      "Epoch 162/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1021596077.0000 - mean_squared_logarithmic_error: 5.1484\n",
      "Epoch 163/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1020548732.0000 - mean_squared_logarithmic_error: 5.1310\n",
      "Epoch 164/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 1019521626.0000 - mean_squared_logarithmic_error: 5.1152\n",
      "Epoch 165/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1018473201.0000 - mean_squared_logarithmic_error: 5.1016\n",
      "Epoch 166/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1017463140.0000 - mean_squared_logarithmic_error: 5.0831\n",
      "Epoch 167/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1016541696.5000 - mean_squared_logarithmic_error: 5.0829\n",
      "Epoch 168/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 1015457404.0000 - mean_squared_logarithmic_error: 5.0773\n",
      "Epoch 169/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 1014442752.0000 - mean_squared_logarithmic_error: 5.0692\n",
      "Epoch 170/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 1013517836.0000 - mean_squared_logarithmic_error: 5.0563\n",
      "Epoch 171/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 1012447242.0000 - mean_squared_logarithmic_error: 5.0437\n",
      "Epoch 172/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1011524422.0000 - mean_squared_logarithmic_error: 5.0301\n",
      "Epoch 173/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1010654218.0000 - mean_squared_logarithmic_error: 5.0250\n",
      "Epoch 174/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 1009553513.0000 - mean_squared_logarithmic_error: 5.0235\n",
      "Epoch 175/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 1008566752.0000 - mean_squared_logarithmic_error: 5.0087\n",
      "Epoch 176/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 1007645356.0000 - mean_squared_logarithmic_error: 4.9948\n",
      "Epoch 177/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 96us/sample - loss: 1006693934.0000 - mean_squared_logarithmic_error: 4.9817\n",
      "Epoch 178/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1005730682.0000 - mean_squared_logarithmic_error: 4.9716\n",
      "Epoch 179/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1004817676.0000 - mean_squared_logarithmic_error: 4.9701\n",
      "Epoch 180/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1003854032.0000 - mean_squared_logarithmic_error: 4.9657\n",
      "Epoch 181/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 1002958290.0000 - mean_squared_logarithmic_error: 4.9727\n",
      "Epoch 182/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 1002057549.0000 - mean_squared_logarithmic_error: 4.9594\n",
      "Epoch 183/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 1001172061.5000 - mean_squared_logarithmic_error: 4.9537\n",
      "Epoch 184/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 1000167334.0000 - mean_squared_logarithmic_error: 4.9501\n",
      "Epoch 185/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 999322752.0000 - mean_squared_logarithmic_error: 4.9509\n",
      "Epoch 186/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 998367852.0000 - mean_squared_logarithmic_error: 4.9478\n",
      "Epoch 187/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 997531240.0000 - mean_squared_logarithmic_error: 4.9406\n",
      "Epoch 188/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 996546433.0000 - mean_squared_logarithmic_error: 4.9466\n",
      "Epoch 189/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 995709132.0000 - mean_squared_logarithmic_error: 4.9331\n",
      "Epoch 190/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 994798227.0000 - mean_squared_logarithmic_error: 4.9315\n",
      "Epoch 191/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 993939400.0000 - mean_squared_logarithmic_error: 4.9199\n",
      "Epoch 192/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 993073787.0000 - mean_squared_logarithmic_error: 4.9117\n",
      "Epoch 193/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 992290861.0000 - mean_squared_logarithmic_error: 4.9073\n",
      "Epoch 194/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 991325656.0000 - mean_squared_logarithmic_error: 4.8852\n",
      "Epoch 195/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 990476616.0000 - mean_squared_logarithmic_error: 4.8736\n",
      "Epoch 196/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 989604881.0000 - mean_squared_logarithmic_error: 4.8550\n",
      "Epoch 197/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 988771320.5000 - mean_squared_logarithmic_error: 4.8448\n",
      "Epoch 198/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 988009346.0000 - mean_squared_logarithmic_error: 4.8455\n",
      "Epoch 199/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 987074052.0000 - mean_squared_logarithmic_error: 4.8397\n",
      "Epoch 200/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 986241529.0000 - mean_squared_logarithmic_error: 4.8309\n",
      "Epoch 201/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 985476968.0000 - mean_squared_logarithmic_error: 4.8355\n",
      "Epoch 202/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 984566009.0000 - mean_squared_logarithmic_error: 4.8318\n",
      "Epoch 203/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 983753832.0000 - mean_squared_logarithmic_error: 4.8253\n",
      "Epoch 204/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 982963840.0000 - mean_squared_logarithmic_error: 4.8162\n",
      "Epoch 205/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 982153024.0000 - mean_squared_logarithmic_error: 4.8129\n",
      "Epoch 206/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 981321982.0000 - mean_squared_logarithmic_error: 4.8130\n",
      "Epoch 207/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 980477936.0000 - mean_squared_logarithmic_error: 4.8057\n",
      "Epoch 208/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 979680626.0000 - mean_squared_logarithmic_error: 4.7906\n",
      "Epoch 209/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 978879320.0000 - mean_squared_logarithmic_error: 4.7804\n",
      "Epoch 210/250\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 978106242.0000 - mean_squared_logarithmic_error: 4.7810\n",
      "Epoch 211/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 977284945.5000 - mean_squared_logarithmic_error: 4.7845\n",
      "Epoch 212/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 976536383.0000 - mean_squared_logarithmic_error: 4.7815\n",
      "Epoch 213/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 975704657.5000 - mean_squared_logarithmic_error: 4.7876\n",
      "Epoch 214/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 974916567.0000 - mean_squared_logarithmic_error: 4.7870\n",
      "Epoch 215/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 974184166.0000 - mean_squared_logarithmic_error: 4.7801\n",
      "Epoch 216/250\n",
      "8000/8000 [==============================] - 1s 130us/sample - loss: 973370970.0000 - mean_squared_logarithmic_error: 4.7789\n",
      "Epoch 217/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 972656956.0000 - mean_squared_logarithmic_error: 4.7754\n",
      "Epoch 218/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 971888810.0000 - mean_squared_logarithmic_error: 4.7712\n",
      "Epoch 219/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 971035926.0000 - mean_squared_logarithmic_error: 4.7775\n",
      "Epoch 220/250\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 970252370.0000 - mean_squared_logarithmic_error: 4.7734\n",
      "Epoch 221/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 969489236.0000 - mean_squared_logarithmic_error: 4.7702\n",
      "Epoch 222/250\n",
      "8000/8000 [==============================] - 1s 135us/sample - loss: 968784724.0000 - mean_squared_logarithmic_error: 4.7725\n",
      "Epoch 223/250\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 967966759.0000 - mean_squared_logarithmic_error: 4.7651\n",
      "Epoch 224/250\n",
      "8000/8000 [==============================] - 1s 126us/sample - loss: 967187692.0000 - mean_squared_logarithmic_error: 4.7628\n",
      "Epoch 225/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 966498275.0000 - mean_squared_logarithmic_error: 4.7556\n",
      "Epoch 226/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 965681965.0000 - mean_squared_logarithmic_error: 4.7487\n",
      "Epoch 227/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 964945584.0000 - mean_squared_logarithmic_error: 4.7487\n",
      "Epoch 228/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 964192709.0000 - mean_squared_logarithmic_error: 4.7509\n",
      "Epoch 229/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 963435749.0000 - mean_squared_logarithmic_error: 4.7424\n",
      "Epoch 230/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 962747376.0000 - mean_squared_logarithmic_error: 4.7346\n",
      "Epoch 231/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 962004939.0000 - mean_squared_logarithmic_error: 4.7298\n",
      "Epoch 232/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 961311321.0000 - mean_squared_logarithmic_error: 4.7298\n",
      "Epoch 233/250\n",
      "8000/8000 [==============================] - 1s 139us/sample - loss: 960576884.0000 - mean_squared_logarithmic_error: 4.7234\n",
      "Epoch 234/250\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 959797653.0000 - mean_squared_logarithmic_error: 4.7290\n",
      "Epoch 235/250\n",
      "8000/8000 [==============================] - 1s 138us/sample - loss: 959063120.0000 - mean_squared_logarithmic_error: 4.7242\n",
      "Epoch 236/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 126us/sample - loss: 958420554.0000 - mean_squared_logarithmic_error: 4.7159\n",
      "Epoch 237/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 957755046.0000 - mean_squared_logarithmic_error: 4.7181\n",
      "Epoch 238/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 956911396.0000 - mean_squared_logarithmic_error: 4.7177\n",
      "Epoch 239/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 956201760.0000 - mean_squared_logarithmic_error: 4.7154\n",
      "Epoch 240/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 955487913.0000 - mean_squared_logarithmic_error: 4.7161\n",
      "Epoch 241/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 954832837.0000 - mean_squared_logarithmic_error: 4.7098\n",
      "Epoch 242/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 954095081.0000 - mean_squared_logarithmic_error: 4.7097\n",
      "Epoch 243/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 953429764.0000 - mean_squared_logarithmic_error: 4.7117\n",
      "Epoch 244/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 952724436.0000 - mean_squared_logarithmic_error: 4.7092\n",
      "Epoch 245/250\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 951990611.0000 - mean_squared_logarithmic_error: 4.7063\n",
      "Epoch 246/250\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 951495176.0000 - mean_squared_logarithmic_error: 4.7038\n",
      "Epoch 247/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 950623354.0000 - mean_squared_logarithmic_error: 4.7011\n",
      "Epoch 248/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 949934732.0000 - mean_squared_logarithmic_error: 4.7062\n",
      "Epoch 249/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 949252496.0000 - mean_squared_logarithmic_error: 4.7103\n",
      "Epoch 250/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 948607856.0000 - mean_squared_logarithmic_error: 4.7031\n"
     ]
    }
   ],
   "source": [
    "TwoPowerTraining = Training_Tensorflow(OutputVector='2^Addition')\n",
    "TwoPowerTraining.TrainTheModel(optimizer='adam',activation='selu',epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7082.28"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwoPowerTraining.PredictOneVal(A=2,B=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like it is not working much for this one either. Time for you to roll up tricks from your sleeves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us do classification on the final column and call it bye for this csv file. \n",
    "### To do that first we have to replace odd and even with 0 and 1 in the DF and thus we modify the class slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Tensorflow_Classification:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 A = Master_DF.A, \n",
    "                 B = Master_DF.B, \n",
    "                 OutputVector=None, \n",
    "                 ClassificationOrRegression=\"Regression\"):\n",
    "        \n",
    "        self.Master_DF_Classification = Master_DF.copy()\n",
    "        self.Master_DF_Classification.replace(\"Odd\",0,inplace=True)\n",
    "        self.Master_DF_Classification.replace(\"Even\",1,inplace=True)\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.OutputVector = OutputVector\n",
    "        self.TypeOfTraining = ClassificationOrRegression\n",
    "        self.Training_DF = None\n",
    "        self.Test_DF = None\n",
    "        self.Model = None\n",
    "        self.Predicted_DF = None\n",
    "        self.TrainTestSplit()\n",
    "        \n",
    "    def TrainTestSplit(self, TestFractionSize=0.2):\n",
    "        self.Training_DF, self.Test_DF = train_test_split(self.Master_DF_Classification, test_size=TestFractionSize)\n",
    "        \n",
    "    def TrainTheModel(self, DenseNodeSize = 1000, batch_size=500, epochs=25, activation='linear',optimizer='sgd', loss='mean_squared_error'):\n",
    "        self.Model = tf.keras.Sequential()\n",
    "        self.Model.add(keras.layers.Dense(DenseNodeSize, activation='selu'))\n",
    "        self.Model.add(keras.layers.Dense(DenseNodeSize, activation=activation))\n",
    "        self.Model.compile(optimizer=optimizer,loss=loss,metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "        xs = np.array([(a,b) for a,b in zip(self.Training_DF.A,self.Training_DF.B)])\n",
    "        ys = np.array(self.Training_DF[self.OutputVector], dtype='float')\n",
    "        self.Model.fit(xs,ys,batch_size=batch_size,epochs=epochs)\n",
    "        \n",
    "    def PredictTheResult(self):\n",
    "        self.Predicted_DF = pd.DataFrame(columns=['InputVals','PredictedVals','Difference'],dtype='float')\n",
    "        self.Predicted_DF.InputVals = self.Test_DF[self.OutputVector]\n",
    "        xs = np.array([(a,b) for a,b in zip(self.Test_DF.A,self.Test_DF.B)])\n",
    "        self.Predicted_DF.PredictedVals = self.Model.predict(xs)[:len(self.Test_DF)]\n",
    "        self.Predicted_DF.Difference = self.Predicted_DF.InputVals - self.Predicted_DF.PredictedVals\n",
    "        \n",
    "    def PredictOneVal(self, A=None, B=None):\n",
    "        return np.round(self.Model.predict(np.array([[A,B]]))[0][0],2)\n",
    "    \n",
    "    def PlotThePredicted_DF(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(self.Test_DF)),self.Predicted_DF.Difference)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/250\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.4901 - binary_crossentropy: 3.4405\n",
      "Epoch 2/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.4396\n",
      "Epoch 3/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4385\n",
      "Epoch 4/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4371\n",
      "Epoch 5/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.4901 - binary_crossentropy: 3.4357\n",
      "Epoch 6/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.4342\n",
      "Epoch 7/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.4327\n",
      "Epoch 8/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.4311\n",
      "Epoch 9/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4296\n",
      "Epoch 10/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4281\n",
      "Epoch 11/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4266\n",
      "Epoch 12/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.4252\n",
      "Epoch 13/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4238\n",
      "Epoch 14/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.4224\n",
      "Epoch 15/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.4211\n",
      "Epoch 16/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4198\n",
      "Epoch 17/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4186\n",
      "Epoch 18/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4174\n",
      "Epoch 19/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4163\n",
      "Epoch 20/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4152\n",
      "Epoch 21/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4142\n",
      "Epoch 22/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.4132\n",
      "Epoch 23/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.4122\n",
      "Epoch 24/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.4113\n",
      "Epoch 25/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.4104\n",
      "Epoch 26/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.4096\n",
      "Epoch 27/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.4088\n",
      "Epoch 28/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4901 - binary_crossentropy: 3.4081\n",
      "Epoch 29/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.4074\n",
      "Epoch 30/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.4067\n",
      "Epoch 31/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.4901 - binary_crossentropy: 3.4060\n",
      "Epoch 32/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.4054\n",
      "Epoch 33/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.4049\n",
      "Epoch 34/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.4043\n",
      "Epoch 35/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.4038\n",
      "Epoch 36/250\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.4901 - binary_crossentropy: 3.4033\n",
      "Epoch 37/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.4028\n",
      "Epoch 38/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.4023\n",
      "Epoch 39/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.4019\n",
      "Epoch 40/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.4015\n",
      "Epoch 41/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.4011\n",
      "Epoch 42/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.4008\n",
      "Epoch 43/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.4004\n",
      "Epoch 44/250\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 0.4901 - binary_crossentropy: 3.4001\n",
      "Epoch 45/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3998\n",
      "Epoch 46/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.3995\n",
      "Epoch 47/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3992\n",
      "Epoch 48/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3989\n",
      "Epoch 49/250\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.4901 - binary_crossentropy: 3.3987\n",
      "Epoch 50/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3984\n",
      "Epoch 51/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3982\n",
      "Epoch 52/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3980\n",
      "Epoch 53/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3978\n",
      "Epoch 54/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3976\n",
      "Epoch 55/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3974\n",
      "Epoch 56/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3972\n",
      "Epoch 57/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3970\n",
      "Epoch 58/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3969\n",
      "Epoch 59/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3967\n",
      "Epoch 60/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3966\n",
      "Epoch 61/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3965\n",
      "Epoch 62/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3963\n",
      "Epoch 63/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3962\n",
      "Epoch 64/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3961\n",
      "Epoch 65/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3960\n",
      "Epoch 66/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3959\n",
      "Epoch 67/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3958\n",
      "Epoch 68/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3957\n",
      "Epoch 69/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4901 - binary_crossentropy: 3.3955\n",
      "Epoch 71/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3954\n",
      "Epoch 72/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.3953\n",
      "Epoch 73/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3952\n",
      "Epoch 74/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.4901 - binary_crossentropy: 3.3952\n",
      "Epoch 75/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3951\n",
      "Epoch 76/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3950\n",
      "Epoch 77/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.3950\n",
      "Epoch 78/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.3949\n",
      "Epoch 79/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3949\n",
      "Epoch 80/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3948\n",
      "Epoch 81/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3948\n",
      "Epoch 82/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.3947\n",
      "Epoch 83/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.3947\n",
      "Epoch 84/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3946\n",
      "Epoch 85/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3946\n",
      "Epoch 86/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.4901 - binary_crossentropy: 3.3945\n",
      "Epoch 87/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.3945\n",
      "Epoch 88/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.3945\n",
      "Epoch 89/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3944\n",
      "Epoch 90/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3944\n",
      "Epoch 91/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3944\n",
      "Epoch 92/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3943\n",
      "Epoch 93/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4901 - binary_crossentropy: 3.3943\n",
      "Epoch 94/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3943\n",
      "Epoch 95/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3942\n",
      "Epoch 96/250\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.4901 - binary_crossentropy: 3.3942\n",
      "Epoch 97/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3942\n",
      "Epoch 98/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3942\n",
      "Epoch 99/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.3941\n",
      "Epoch 100/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3941\n",
      "Epoch 101/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.4901 - binary_crossentropy: 3.3941\n",
      "Epoch 102/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.3941\n",
      "Epoch 103/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3941\n",
      "Epoch 104/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 105/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 106/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 107/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 108/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 109/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3940\n",
      "Epoch 110/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 111/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 112/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 113/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 114/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 115/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 116/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 117/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3939\n",
      "Epoch 118/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 119/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 120/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 121/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 122/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 123/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 124/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 125/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 126/250\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 127/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 128/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3938\n",
      "Epoch 129/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 130/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 131/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 132/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 133/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 134/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 135/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 136/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 137/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 138/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 139/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 140/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 141/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 142/250\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 143/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 144/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 145/250\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 146/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3937\n",
      "Epoch 147/250\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 148/250\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 149/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 150/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 151/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 152/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 153/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 154/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 155/250\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 156/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 157/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 158/250\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 159/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 160/250\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 161/250\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 162/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 163/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 164/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 165/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 166/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 167/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 168/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 169/250\n",
      "8000/8000 [==============================] - 1s 120us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 170/250\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 171/250\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 172/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 173/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 174/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 175/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 176/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 177/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 178/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 179/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 180/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 181/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3936\n",
      "Epoch 182/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 183/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 184/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 185/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 186/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 187/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 188/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 189/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 190/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 191/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 192/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 193/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 194/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 195/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 196/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 197/250\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 198/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 199/250\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 200/250\n",
      "8000/8000 [==============================] - 1s 118us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 201/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 202/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 203/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 204/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 205/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 206/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 207/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 208/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 209/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 210/250\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 211/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 212/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 213/250\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 214/250\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 215/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 216/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 217/250\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 218/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 219/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 220/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 221/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 222/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 223/250\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 224/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 225/250\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 226/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 227/250\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 228/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 229/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 230/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 231/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 232/250\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 233/250\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 234/250\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 235/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 236/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 237/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 238/250\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 239/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 240/250\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 241/250\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 242/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 243/250\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 244/250\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 245/250\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 246/250\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 247/250\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 248/250\n",
      "8000/8000 [==============================] - 1s 111us/sample - loss: 0.4901 - binary_crossentropy: 3.3935\n",
      "Epoch 249/250\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.4901 - binary_crossentropy: 3.3934\n",
      "Epoch 250/250\n",
      "8000/8000 [==============================] - 1s 115us/sample - loss: 0.4901 - binary_crossentropy: 3.3934\n"
     ]
    }
   ],
   "source": [
    "OddEvenTraining = Training_Tensorflow_Classification(OutputVector='ODD_OR_EVEN(CEIL(A+B))')\n",
    "OddEvenTraining.TrainTheModel(activation='softmax',optimizer='adam',epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OddEvenTraining.PredictOneVal(A=5,B=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OddEvenTraining.PredictOneVal(A=5,B=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
